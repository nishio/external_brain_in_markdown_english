---
title: "AI Agents and De-turned Communication"
---

from  [[Diary 2025-02-10]]
- [[AI Agents]] and De-turn Communication
> [teramotodaiki](https://x.com/teramotodaiki/status/1888620661092089920) I'm not sure if this is what an agent search looks like, but I've tried to make it in an uninformed way.
>  ・All o3-mini is fine. I don't need any other model.
>  ・Building reliable knowledge is everything. Everything else is trivial.
>  ・Serverless (stateless?) architecture If you assume a serverless (stateless?) architecture, you can only do turn-based communication, which is shoddy.
>  ・Devin is amazing!

> [teramotodaiki](https://x.com/teramotodaiki/status/1888621918045315238) I think 99% of developers think that ChatGPT is [[turn-based communication]] and "that's the way it is". I think 99% of developers think "that's the way it is" because ChatGPT is [[turn-based communication]].
>  Devin is seriously good at designing sessions; he's "in" the Slack thread. You have to rethink the architecture to create that experience.

> [teramotodaiki](https://x.com/teramotodaiki/status/1888623326010163675) In a broader sense, this may be another memory design. To what extent does it take over the memory? The design of a kind of self-identity. UI to match the user's expected identity with the design of the software...
>  I'm having fun getting this deep into human cognition through software development.

I'm very torn here, but I think it would actually be a form of non-turn-based communication, because it's not like people are talking to each other on KINTONE, nor are they taking turns talking to each other.

What we mean here by "turn-based communication" is "Mr. A talks, Mr. B talks, Mr. A talks, ..." that is, "Mr. A speaks, Mr. B speaks, Mr. A speaks, ...".
The architecture is easy because AI only needs to respond to human input, but that doesn't make it [[Devin-like]].
Mr. A can talk about N things, Mr. B can talk about M things, and just because Mr. A talks doesn't mean it's Mr. B's turn to talk.
This is exactly what human conversations in kintone, etc. are like, and this way of interacting is different from ChatGPT, isn't it?

[[Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance]]
[[Proactive Agent]]

---
This page is auto-translated from [/nishio/AIエージェントと脱ターン制コミュニケーション](https://scrapbox.io/nishio/AIエージェントと脱ターン制コミュニケーション) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.