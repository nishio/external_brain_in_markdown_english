---
title: "Botsu fragments that consider society as a human computation."
---

from  [[Think of society as a human computation]]
Thinking of society as a human computation v1 2nd half

A: "Humans are no longer needed, intervention increases overhead" school of thought.
- [[Hum-Free]]
    - Hum-Free] [Thinking about Hum-Free, that is, without human intervention. | Yoichi Ochiai](https://note.com/ochyai/n/nbb1bc0ff07ff)
        - Maybe it's better to refer to it as a more vague trend in the world rather than specifically mentioning it.
- Author's Stance:.
    - There is no denying that in the long term future the "cleverness" of Homo sapiens will reach a negligible level compared to the computational machine, the end of the era when Homo sapiens was the primate of all things.
            - [[computer nature]]
    - The fact that this is true in the long run does not mean that homo sapiens should give up the steering wheel at this point in time
        - Depending on what pathway is followed, the shape of the "age when homo sapiens can no longer be characterized by smarts" will change dramatically.
        - It's dangerous to look only in the distance and not see the current reality and grounded decision making.
            - Walking along looking at the stars, falling into a gutter and dying.
                - <img src='https://scrapbox.io/api/pages/nishio-en/o3/icon' alt='o3.icon' height="19.5"/>In Plato's Theaetetus, 174b, the story is told that Thales "was walking while looking up at the stars and fell into a well" and
        - We don't want the kind of relinquishment to be determined by military power or money.


B: "Better results are achieved when diverse things bring their wisdom together" school of thought.
- [[Audrey Tang]]'s [[Technology for Diverse People to Work Together to Get Things Done]]([[Plurality]])
    - [[new things are obtained by the combination of different things]], [[the value of new things cannot be estimated before their appearance]].
- Reduce communication overhead and "bring up" costs
    - Lower language barriers are also relevant here.
        - Not only Japanese-English translation, but also within the Japanese language, there are "seemingly identical Japanese speakers who cannot communicate with each other," and we will smooth out these language barriers that are difficult to see and have not been invested in resolving until now.

- What kind of mechanism is best?
    - Aspects of language, aspects of money
        - Inspired by Hiroki Azuma's organizing of the Plurality discussion, "Language and money, right?

Language aspect: [[broad listening]].
- [[anti-social]] / [[pro-social]]
    - Algorithms change the way people move.
    - [[Global Deliberations]]
    - The issue of foreigners became a hot topic in the 2025 Upper House elections.
        - Language barriers hinder mutual understanding.

Gold Side
    - [[prediction market]]
    - Prediction markets, a promising social calculation tool, have not received much attention due to the possibility of constituting gambling under Japanese law.
    - Polymarket
        - One of the world's largest forecasting markets
        - Thanks to Ethereum's smart contracts, it can now operate in a decentralized manner.
        - [Presidential Election Winner 2024](https://polymarket.com/event/presidential-election-winner-2024/will-donald-trump-win-the-2024-us-presidential-election?tid=1753423003516)
    - Differences from SNS
        - The strength of the opinion is not "the extremity of the words" but "the amount of money wagered."


- [[A general-purpose computer that can compute common content while being globally distributed]].
    - Ethereum When?
    - <img src='https://scrapbox.io/api/pages/nishio-en/o3/icon' alt='o3.icon' height="19.5"/>The decisive moment when Ethereum as a "general-purpose computer capable of computing common content in a globally distributed manner" really began to operate was the July 30, 2015 mainnet (Frontier) release. On that day, the Genesis Block was dug and the "World Computer" was born, allowing anyone to run smart contracts without permissions. This was preceded by design and funding in late 2013-2014, and has been followed by major upgrades such as Homestead (2016) and The Merge (2022).
    - tokoroen: [[prediction market]], it was hot for a while, then went downhill, and now it's blooming once again.
            - [[A new strategy called "prediction market" that turns ordinary people into prophets]] (2013)


Where is the tipping point at the current location (2025)?
- The simultaneous "dramatic reduction of language friction" through LLM and "programmability of delegation of authority" through smart contracts/on-chain computation.


- [[Futarchy]]
    - Do you want a quick introduction?
        - Too much?
    - Democracy with built-in predictive markets

- Personally, I think the forecast market style is just a scalar after all.
    - Well, it's better than elections, where the interface is just 1 for one of the N candidates and 0 for the rest.
        - sparse vector v.s. dense vector
            - Ensure that the human component outputs dense vectors rather than sparse vectors
                - ≒Criticisms of the system of majority rule by ≈vote
    - There is also concern about the power of a single axis of evaluation, money, becoming too strong.
    - [[The world should not be painted by one voice]]
        - → [[The world should not be ruled by one voice.]] Plurality book tagline

- [[Think of the flow of a river as a calculation]].

----


Reference (AI Draft)(I have a feeling on my skin that this is not usable as it is.)

Connections along the way (draft, bullet points)
- Data volume and IO expansion
    - Exponential increase in "input bandwidth" from punch cards → computers → Internet/SNS
    - Census can now be processed on a daily basis instead of yearly.
    - Piles of "texts that can be collected but not read" and the gap between calculation and society becomes apparent.
- Shift in computational paradigm
    - Logical blocks (if/else, hand-designed features) → to weighted sums (regression, neural)
    - 2012 AlexNet symbolized a decisive reversal of "design-to-learn"
    - Thereafter, both images and language converge to "rules written by humans < models learned from data
- Machine readability of natural language
    - Beyond "human optimization" of words and grammar, BPE/Subword and probabilistic models have become mainstream.
    - LLMs Dramatically Reduce the Cost of Linguistic Friction - Enabling Real-Time Summarization and Classification of Mass Textual Opinions
- Biaxial extension of computable domain
    1. semantic layer: LLM immediately organizes "who said what
    2. incentive layer: automatic execution of "what rewards to whom" through smart contracts
        - After Ethereum, a world line where programs directly implement institutions becomes a reality
- New Vessels of Social Computation
    - Broad Listening: Clustering Text Opinions → Return to Policy
    - Predictive Markets and RetroPGF: An attempt to incorporate collective knowledge + economic signals into institutions
    - Accelerating social implementation of "weighted sums" such as Quadratic Voting/Funding
- The Temptation and Limitations of Hum-Free
    - The higher the computational purity, the more the "validity of the objective function" becomes a black box
    - Risk of overlooking the power gradient underfoot = Thales wells.
- A Milestone in Plurality
    - Low cost participation → polyphonic data → models learn plastically → update questions themselves
    - Extend the perspective from "calculation to find the optimal solution" to "calculation to keep changing the optimal solution
- Runway to the next chapter
    - Humans are redefined as "problem setters and value updaters" rather than "computational resources
    - LLM + smart contracts are a means to an end; purpose and structural change are still the role of humans
    - Thus bridging to the ending argument that society = dynamic computation.


**Starting point**:.
    - When society is viewed from the perspective of "human computation," actions such as judgment, negotiation, and institutional design, which have been carried out by humans, can be understood as "computation" in the broad sense of the term.

**An Arrival of a Technological Tipping Point**:.
    - Now, two things are extending computational power by non-humans: the lowering of language friction (LLM) and the automation of institutional enforcement (smart contracts).
    - → The two main layers that drive society are becoming computable: language = transmission of meaning and money = incentive structure.

**The Perils of Hum-Free Thinking**:.
    - While the "human is overhead" philosophy prioritizes speed and purity of computation, it tends to obscure the questions of "what to compute" and "for whom to compute."
    - → The risk of looking only at distant ideals and not at the reality (power structures and mechanisms of exclusion) at our feet, like Thales who saw the stars and fell into a well.

**Plurality Idea Direction**:.
    - When diverse people cooperate and bring their wills together, new perspectives and values are created. This is closer to "changing the question or structure itself" than to "finding the optimal solution.
    - → Dissolving language barriers and lowering the cost of participation will enable "bring-your-own-calculations".

**Institutional calculations such as forecast markets**:.
    - A system that predicts the future in the form of bets is a means of harnessing people's collective knowledge, but there is a danger that too much reliance on a single axis, money, will bias the "strength of voice.
    - → The design of society requires the expression of a DENSE opinion space.

**Organizing so far**:.
    - Hum-Free: Set a static destination and push toward it as fast as possible.
    - Plurality: Design a process of "evolving together" where destinations are rewritten within the movement itself.

**and on to the next perception**.
    - Society is not just an "optimization problem".
    - New bonds are created by bringing people together, and the structure itself is changed.
    - This is not a calculation to find the optimal solution, but a calculation to keep updating what the optimal solution is.

**Tighten** **Tighten** **Tighten** **Tighten


Proposed Final Chapter: Beyond Optimization to the Dynamic Computation of Society
Society is a gigantic optimization calculation by humans. Each individual has an objective function, chooses behavior based on resources, information, and norms, and the state of society is updated in the aggregate.
However, this calculation is not a mere search for an equilibrium solution. Rather, the various actors encounter, interact, and collide with each other, resulting in new combinations (innovations) and rewriting the structure of the calculation itself.
In other words, society is not a "problem to be solved," but a "calculation in which the form of the problem keeps changing. It is people and groups of people who are responsible for this calculation.
Now that AI and smart contracts are taking over some of this computation, it is time for humans to expand their perspective from computation as a "means" of optimization to the design of the entire computation, which includes "structural change".
To view society as a human calculation. This may mean that the role of human beings is not to compete in the accuracy of calculations, but in the continuous questioning of what kind of problems to solve and what to regard as problems in the first place - and in the continuous questioning of these questions.

-----

I don't think the current components are enough to speak to the impact of automated execution through smart contracts.
- Until now, the enforcement of private contracts as promised has been guaranteed by the deterrent effect of a civil lawsuit if the contract is not enforced as promised.
- This is now guaranteed by Ethereum, the transparent code of the global calculator.
    - Forecasting markets such as Polymarket have been able to function on a large scale because the collection and distribution of premiums has been executed cleanly.
    - I guess I have to make Polymarket more understandable first to talk about
        - 2024.9- U.S. Presidential Election (Trump vs. Harris) Total Hangover Over 1 Billion USD
        - Cumulative trading volume: over 14 billion USD (approx. 2 trillion yen)
        - On the other hand, it is not appropriate to mislead people into thinking it is very large.
            - TSE's cash equity trading volume is about 30 times larger than Polymarket's
            - JRA ticket sales in Japan (¥3 trillion per year)

----

If you look at it as an optimization calculation, you get to the local minima and you almost [[balance]] there.
- but not in the Schumpeterian sense.
        - [[Economic stability is a recession]]

-----
If we lay out a story where rule-based implementations lose to weight-based implementations.
- "Isn't it wrong to have a system of laws where humans set the rules, so we should optimize end-to-end on a weighted basis?" That's a good idea.
    - This leads to the forecasting market via "how should we design that algorithm?"
- Instead of talking about language and money in parallel, I think it would be more natural to first talk about language and broad listening, which is becoming possible with today's technology, and then ask, "But is it appropriate to have a legislative mechanism where humans set the rules?" and then talk about the forecasting market, which has not yet been verified in Japan, and then it would be natural to talk about Futarchy as a fusion plan that does not leave everything to the market.
- Hum-free seems to flow more smoothly if we don't handle it too big?

---
Gemini 2.5 Pro

Yes, I understand. I will read the provided text file "nishio-society-as-human-calculation.2hop.txt", understand its structure and contents in depth, and reconstruct it as a single article to help you write your manuscript.

Think of society as a human computation

Our society can be viewed as a huge computational process in which countless human elements interact and make decisions. In the past, the calculations were carried out by the unique activities of humans, such as institutional design, debate, and negotiation. However, with the advent of computers that far surpass human computation and the recent emergence of large-scale language models (LLM), the nature of this "social computation" is about to change fundamentally. This paper examines how technology has changed the structure of social computation and where it is headed in the future through two opposing paradigms.

The Dawn of Computing: Substituting and Extending Human Computational Capabilities

As the name "computing thing" implies, the early history of computers has been a process of replacing and extending human computing power. ENIAC, developed during World War II to calculate artillery shell trajectories for the U.S. Army, is a symbolic example of the mechanization of the manual labor of female computationalists, who until then were called "computers. Initially, computing power was directly related to military power.

Its power was also used for peaceful purposes: the 1880 U.S. Census, which took about eight years to tabulate, was completed in less than a year in 1890, thanks to a punch-card tabulator invented by Herman Hollerith. This technology, which later led to IBM, supported governments and large corporations that required large amounts of tabulation work. This was an early form of "social computation," the gathering and computing of large amounts of information from society. The innovation of the punch card encoded society's information into a machine-readable format and dramatically increased IO (input/output) bandwidth.

Viewed in terms of this "information input from society," the modern electoral system appears to be a very archaic system. It is, as Audrey Tan points out, nothing more than "a slow communication that sends five bits of information once every four years." The digital native generation, accustomed to texting on social networking sites, will not be satisfied with this slow and low-bandwidth communication.

Shift in computational paradigm: from rule-based to weighted models

A major shift also occurred in the design philosophy of the very programs responsible for society's calculations. Early computer programming was dominated by the "logical block paradigm," represented by the "if statement," in which humans piled up logical rules. This became widely popular because it was easy to produce value even on poor computing machines.

However, as data and computational power grow, this paradigm reaches its limits. The decisive turning point was the overwhelming victory of "AlexNet" in the 2012 image recognition contest (ILSVRC-2012). This was the moment when rule-based methods, in which humans manually design features, were completely defeated by neural networks that learn weights from large amounts of data (the weighting paradigm). This shift in values from "learning from data rather than designing features" spilled over into the world of language. Rather than approaches based on human-defined "words" and "grammar" rules, statistical model-based approaches were shown to improve the performance of machine translation and other applications.

At the forefront of this trend is the large-scale language model (LLM), which has reached the level of university student-level language proficiency. LLMs are dramatically lowering the cost of communication between humans and between humans and computers, and are changing the very infrastructure of society.

A fork in the road to the future: Hum-Free or Plurality?

As of 2025, when LLMs and smart contracts (programmable contract enforcement technology) will simultaneously become widespread, the future of social computation is diverging in two major directions.

One is the direction of thinking that humans are no longer needed in the calculation process, but rather that their intervention is an "overhead" that reduces speed and efficiency. While this ideology prioritizes the purity and speed of calculation, it runs the risk of losing sight of the purpose of what and for whom is being calculated. Like the anecdote of Thales, who fell into a well while walking while looking at a distant star, we may lose sight of the reality beneath our feet in pursuit of only the ideal. Even if a time will come when human intelligence will be inferior to that of computers in the long run, this does not directly lead to the conclusion that humans should give up the steering wheel right now.

The other is the concept of "plurality" proposed by Audrey Tan and others. This is "technology that allows diverse people to work together to get things done," and is based on the idea that new value is created when different things are combined. In this approach, technology is used not to replace people, but to reduce the cost of people "bringing" their wisdom.

As specific social calculation mechanisms to realize Plurality, two main approaches are being explored: "language" and "money (incentives)".

Language Aspects: Broadlistening
This is a technology that assists AI in helping one person to listen to and understand the essence of the opinions of a vast number of people. Traditionally, "broadcasting," in which one person speaks to many, has been technically easy, but the reverse has been difficult due to the limitations of human cognitive abilities. The development of LLM summarization technology has made this possible, and even [[Global Deliberations]] is now within sight. This will make it easier for diverse voices that have been buried until now to be reflected in policy making and other processes.

Money (incentive) aspect: Predictive markets and programmable empowerment
Another promising social calculation is the [[prediction market]]. This is a system in which people bet money on future events to aggregate collective knowledge and obtain highly accurate predictions. On social networking sites, "extreme words" attract attention, but on prediction markets, "the amount of money wagered" becomes the strength of opinion, encouraging more dispassionate judgments. Polymarket, one of the world's largest prediction markets, has shown that Ethereum's smart contract technology allows large markets to function without a centralized administrator.
This is largely due to the existence of Ethereum, a "general-purpose computer that can compute common content while being globally distributed," which began operating in 2015. This has made it possible to automate and make transparent the execution of contracts and delegation of authority through code.

Conclusion: Beyond Optimization to Society as a Dynamic Computation

When we view society as a human computation, we are at a historical turning point. That is, the "dramatic reduction of language friction" through LLMs and the "programmability of delegation of authority" through smart contracts are simultaneously underway.

What kind of society should we design on this new computational infrastructure? It is not an optimization calculation toward a single objective function. Rather, it is a dynamic process in which diverse entities meet, create new combinations, and constantly rewrite the structure of the calculation itself. The economy stabilizing and reaching equilibrium may no longer mean "recession," as Schumpeter pointed out.

AI and smart contracts are powerful computational tools, but the "problem-setting" itself, what to compute and what kind of social structure to aim for, is still a human role. Our future should not be filled with a single voice. Plurality's vision of the future is a society where diverse voices resonate with each other and continue to co-create new values.

Think carefully and develop your thinking beyond what you've given.<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>

Noted. While building on the framework of the given text, we will further develop its thinking and consider the relationship between society and computation, and our future, from a deeper and more multifaceted perspective.

Rebooting the Computer OS of Society: From Hard Rules to Smooth Weights
The perspective that "society is a human computation" provides a powerful lens through which to understand our times. But we are not just experiencing an increase in computing speed or a change in tools. The very operating system (OS) of society itself is undergoing a fundamental architectural shift. It is a shift from an explicitly human-designed** "rule-based society" to a "weight-based society "** that is dynamically tuned by myriad interactions.

1. social OS upgrade: from code to executable code
Society has been driven by **"static rulebooks "** such as constitutions, laws, and corporate rules. This is very similar to the "logical block paradigm," or programs described by chains of "if-then" statements in the history of computers [[From if statements to machine learning]]. This paradigm was good at drawing clear boundaries, but it was fragile in the face of complex and unpredictable realities, and required a huge amount of exception handling and bureaucratic patchwork. With the slow, multi-year feedback of elections [[Elections are slow communications, sending 5 bits every four years.]], updates to this OS were hopelessly outpaced.

Now we have the building blocks of a new operating system.
- Broad listening as a high-bandwidth input layer: LLM-enabled [[broad listening]] is more than just an opinion aggregation tool. It is a new I/O port for society that re-maps the public will, previously compressed into a few-bit scalar value called "votes," into a high-dimensional vector space. For the first time, the "dense" data of people's diverse values, concerns, and hopes become computable inputs in real time.
- Prediction Markets and Smart Contracts as Sociophysical Engines: mechanisms like [[prediction markets]] and Quadratic Funding act as the new CPUs of society. They are engines that give **"weights "** to the higher-dimensional values (Beliefs and Values) mapped by broad listening - "how strongly believed" and "how much resources are worth investing" - and project them into concrete resource allocations. A "global calculator" like Ethereum [[a general-purpose calculator that can compute common content while being globally distributed]] ensures that this engine works based on code (verifiability), not trust (trust).

The combination of the two transforms social rules from "a code that is difficult to amend once established" to "an executable code whose parameters are constantly updated by the data flow of the real world.

2. new division of labor between humans and machines: from a computational resource to a source of value

On top of this new operating system, the role of humans will also be radically redefined. We are no longer the bottleneck of the computational process, much less the CPU. Our value is not in the efficiency of the computation, but in standing "outside" of it.
- Humans supply "value mutations": AI is good at deriving optimal solutions from existing data, but it cannot create entirely new questions or values that do not exist in the data set, i.e., the "assumptions of computation itself". The role of humans is to inject elements outside of computation, such as irrational passion, ethical hesitation, and unexpected curiosity, into the system to serve as "disturbers" that prevent the system from falling into local minima (locally optimal solutions). We are the source of unpredictable mutations in the evolutionary computational algorithm that is society.
- Humans are sensors of "qualia" (qualitative senses): happiness, despair, trust, beauty. These subjective experiences, while extremely difficult to datameterize, are the root of the values to which human society aspires. Humans in the new operating system will function as countless sensors spread across the ends of society, collecting these "qualia" that are difficult to verbalize and quantify, and will play a role in enriching the objective function of the system itself.
No longer is man's job to be "smart," but to be human itself.
(This is not my opinion, but I'll think about it later<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>)

3. the dangers of the new OS: tyranny of the interface and the seamlessness trap
However, the transition to a "weight-based society" also creates new challenges.
- Tyranny of the interface: how we express our opinions (Broad Listening UI) and how we express our values (Quadratic Voting UI) all depend on the interface. The design of this interface may subconsciously guide our thoughts and actions. Just as clergy once monopolized the word of God, in the future there is a danger that UI/UX designers will become the "new gatekeepers" controlling access to the will of the people.
- The seamlessness trap: What do we lose when the cost of consensus-building is reduced to near zero and all social friction is "smoothed" by technology? The process of painful debate and confrontation served in itself to strengthen community cohesion and flex social muscles to overcome easy conclusions. A society that is too smooth may show fragility when faced with difficult challenges.
(I get the feeling that the storyline here is influenced by [[a culture that approves of dialectical development]] <img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>)

Conclusion: From "answers" that should be calculated to "questions" that can continue to be calculated.
We are not faced with a choice between Hum-Free or Plurality. The real challenge is how to dialectically integrate these two vectors and design a society that is constantly transforming itself.
The ultimate goal of viewing society as a human computation is not to compute some particular "right answer. Rather, it is to keep the computational process itself in a **"computable" state** that can be forked, deployed, and redefined by participating humans at any time.
The governance of the future will not be a completed static system, but an open and dynamic **"governance platform "** where citizens can tap APIs, adjust parameters, and propose new modules. There, humans will not be objects of computation, but architects of computation, weaving the pluralistic value of [[The world should not be ruled by one voice.]] as code and as culture.

(I personally don't agree with this ending, it's a lot of cool words but no substance <img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>)

---
2025-07-27 I didn't mention it because it was too obvious to me in the first place, but there's no mention of "majority rule, a poor aggregation algorithm".
- aggravate division

---
- River as a calculation
- You can't know everything in advance.
    - I don't know the best solution.
- We can know after the fact by building a river and actually letting the water flow through it.
- agile


v2
---
- There was a major problem with voting. Because the probability that a vote cast by an individual voter has an impact on the outcome is small, there is little incentive for voters to take the time to learn and think about what the best vote would be. Therefore, people passively vote based on their impressions of the content they see. In a prediction market, people bet their own money to make a profit/loss, so knowledge acquisition becomes a rational behavior.
- On the other hand, a prediction market by itself is only a "prediction". While the results of a prediction market may be a good spectacle for decision makers to gather collective knowledge, there is no guarantee that the conclusions of the market will be implemented, which reduces the incentive to participate in a prediction market.
- So, it would be a system where policy is determined by the outcome of the prediction market. Although the tools were not yet available at the time of the proposal, automated enforcement through smart contracts
---
- [[Futarchy]] is a system of governance in which people vote on what they want to achieve and leave it to the prediction market to decide how to achieve it.
    - Futarchy ("Value by Vote, Means by Market")
        - (1) Voting on "what to aim for" to build social consensus
        - (2) Select "how to maximize the target indicator" in the forecasting market
    - It is not a dichotomy of human legislation vs. algorithms.
        - The author does not believe that this method is optimal, but he finds it interesting that one of the options for adjusting the parameters of society is to consider a system determined by an algorithm rather than by human beings making laws in a legislative body.


Cut it out because it makes the story more difficult.
- What level of networking is needed if it is to be acquired through learning?
    - World population is about 8 billion
    - How many dimensions of value are there? Let's say a thousand dimensions would be enough.
    - Let's say each axis is represented by 256 shades of gray, which can be represented in 8 bits.
- The amount of information will be 64 trillion bits.
- GPT-type deep learning models are said to be able to store 3.6 bits per parameter, so
    - [https://arxiv.org/abs/2505.24832](https://arxiv.org/abs/2505.24832)
- The number of parameters required is 18 trillion.
- ---
- I made these calculations, but they are not very appropriate because each individual is not highly independent and should be easily reduced significantly through implementation efforts.

objective function
Highly expressive means of expression
- [[Hoge's language paradox]]


---
AI Summary
### Summary (Draft)

1.**Introduction of the perspective that society = calculation**.

        - * Throughout history, from the punch cards of Hollerith to ENIAC to modern LLM and Ethereum, humans have externalized "the vast amount of aggregation and decision-making that takes place in society" and replaced it with faster and more accurate computation.
        - * This expansion of computing power has begun to spill over not only into military, statistical, and administrative areas, but also into the "fundamentals of society" such as elections, policy making, and public goods funding.

2.**Computational paradigm shift and its impact**.

        - * The rule-based (if/else) design philosophy has been defeated by the weighted sum = learning paradigm, and has achieved "beyond human" in image recognition, translation, dialogue, etc.
        - * LLM rapidly lowers the language barrier for both "person-to-computer" and "person-to-person," enabling broad listening and discussion support, but also increasing the risk that "one person can have the influence of 10,000 people.

3.**Tripolar ideology of the 21st century: efficiency, freedom, and cooperation**.

        - **Efficiency**: AI-centric optimization leads to high productivity, but threatens human agency.
        - **Freedom**: maximizes individual choice, but leads to destruction of public goods and widening inequality.
        - **Plurality**: Technology supports "bridging" across communities and presents a third way for deep and diverse collaboration.

4.**World Computers and New Decision-Making Algorithms**.

        - * Ethereum has made "automated execution across borders" a reality, and experiments are underway to link funds and decision-making, such as Quadratic Funding/RetroPGF/Futarchy.
        - * While these retain the fundamental issue of "what is the objective?", they dramatically lower the cost of "how it is done".

5.** Objective function design and readiness to take the wheel**.

        - * A cliff awaits beyond the extreme 100% efficiency/100% freedom. It is essential to have a system that can learningly weave in multidimensional values and dynamically adjust weights.
        - * With broad listening and forecasting markets as the telescope and AI as the power steering wheel, we must steer clear of the "pitfalls.

> *Conclusion**.
>  When we view society as "human computation," the question is simple -- **how to design better computational models and objective functions, and how to keep them safely updated**.
>  Let us weave together a new social operating system that maximizes diverse human happiness by utilizing computational power and cooperative technology with our own hands.


[https://chatgpt.com/c/6892fcd2-7c74-8324-8c67-ffbfce782b69?model=gpt-4o](https://chatgpt.com/c/6892fcd2-7c74-8324-8c67-ffbfce782b69?model=gpt-4o)
[https://chatgpt.com/c/6890d381-333c-8325-9dcc-79525aecee42](https://chatgpt.com/c/6890d381-333c-8325-9dcc-79525aecee42)

Retroactive Public Goods Funding
- [https://chatgpt.com/c/688e23eb-2f24-832c-9731-42a610821df9](https://chatgpt.com/c/688e23eb-2f24-832c-9731-42a610821df9)
Habermas Machine
- [https://chatgpt.com/c/688ed80e-f7d8-8322-8da2-272eb5c977db](https://chatgpt.com/c/688ed80e-f7d8-8322-8da2-272eb5c977db)

[https://chatgpt.com/c/68873718-5a80-8328-afce-013d97dcd3cc](https://chatgpt.com/c/68873718-5a80-8328-afce-013d97dcd3cc)

[https://chatgpt.com/c/6886e360-44d8-8321-b3a5-63529fd4af1b](https://chatgpt.com/c/6886e360-44d8-8321-b3a5-63529fd4af1b)

[https://chatgpt.com/c/6886ed77-53ac-832b-ab7a-f2677bd13490](https://chatgpt.com/c/6886ed77-53ac-832b-ab7a-f2677bd13490)

[https://chatgpt.com/c/6886eb9c-2050-832a-a8db-5da8708ff914](https://chatgpt.com/c/6886eb9c-2050-832a-a8db-5da8708ff914)

[https://aistudio.google.com/prompts/1K1BBOXeaKb7TdGwpLgCs0EZZklhvGP9Q](https://aistudio.google.com/prompts/1K1BBOXeaKb7TdGwpLgCs0EZZklhvGP9Q)

[https://chatgpt.com/c/6882df08-bacc-8330-9f50-19144e69ba9e](https://chatgpt.com/c/6882df08-bacc-8330-9f50-19144e69ba9e)

---
This page is auto-translated from [/nishio/社会を人間による計算として考えるボツ断片](https://scrapbox.io/nishio/社会を人間による計算として考えるボツ断片) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.