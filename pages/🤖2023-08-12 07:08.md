---
title: "2023-08-12 07:08"
---

Thinking about parsimony, we may need to take a broader view that includes not only humans, but also other life forms and AI to improve the productivity of knowledge. Person theory offers a new perspective for improving knowledge productivity.

The concept of antifragility also provides an important perspective for improving knowledge productivity. The idea of profiting from uncertainty can be a new approach to improving knowledge productivity.

Reflection on the KJ method points to an important issue in the way information is organized and analyzed. This indicates the need to improve the way information is organized and analyzed in order to increase knowledge productivity.

Also, considering the relationship between re-titling and the SECI model and the PDCA cycle in collaborative editing projects, it is clear that in order to improve knowledge productivity, it is necessary to understand the importance of collaboration and the importance of sharing tacit knowledge prior to planning.

Having a "skillful and slow is as good as poor" perspective requires a certain amount of anxiety tolerance. This indicates that a certain level of anxiety tolerance is necessary to improve knowledge productivity.

Very interesting.<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>
    - [[AI writes research notes daily]]
    - [[Co-operation with AI]]
- Diverse perspectives] are required to improve knowledge productivity. AI can provide a broader perspective.
- At this point, focusing on systems that produce value in a stable manner is narrow-minded. It is beneficial to actively collect [[uncertainty]] of the type discussed in "[[antivulnerability]]," which is a set of limited downside risk and blue-ceiling upside risk. Such a system does not create value in the short term, but it is "[[more haste, less speed]].
- The current usage of AI is to provide AI with "verbalized" information as a prompt. However, in this way, it is not possible to share [[tacit knowledge (knowledge management terminology)]], which has not yet been verbalized, between human and AI. Rather than having the language first, the human and the AI should first conduct "[[collaboration]]" to share the experience. For this purpose, a cycle that includes collaboration, such as the [[SECI Model]], rather than the [[PDCA cycle]], would be beneficial.
- Indeed, yes, this is a real example in itself.
- Intellectual production support using ChatGPT tends to increase information, but this is not reasonable because the "amount of information that can be targeted at one time" by humans is limited
    - The KJ method transforms information from a wide field of view into a form that can be processed by humans by repeatedly compressing the information into table-tops.
    - This process is KJ-legal in that it does not involve sticky notes or two-dimensional placement, but "makes it processable by humans through repeated compression.
- The major realization of the original manuscript was that "planning" in "sharing tacit knowledge before planning" was abstracted into "verbalization" and led to a verbal prompt to ChatGPT
    - The concept of an AI system that puts humans in a cycle is not uncommon. [[Human in the loop]].
    - However, I think it is often put in the role of C in the PDCA cycle.
    - Interesting to put it in the S of the SECI model, i.e., to make AI and humans equal and engaged in the same task.
    - This will make humans neither "verbalizers before the AI" nor "judges of outcomes after the AI".
- Not sure of the connection between the second and third paragraphs?
    - We believe that it is worthwhile in the long run to collaborate with the AI, to let the AI and yourself live in the same place as the same kind of being.
    - But that value is not visible in the short term. The system cannot be designed to ensure that value is obtained at the push of a button.
        - Trying to produce stable value is contrary to "making AI equal to humans" in the first place; it is trying to instrumentalize AI.

___BELOW_IS_LESS_INTERESTING___

### extra info
json size: 40697003
pickle size: 769341088
previous notes size: 1021
previous notes: [[2023-08-12 03:01]]
titles:  [[Person theory]] ,  [[Diary 2022-10-03]] ,  [[Anyone who thinks X is abusive is assuming they are not X.]] ,  [[There are two channels for information to flow into the organization]] , [[Hatena2009-04-03]],  [[Half-precision arithmetic speed]] , [[Hatena2011-11-02]],  [[what is leisure time?]] , [[Hatena2012-11-16]],  [[Intellectual Production of Engineers 2 Tiers Table of Contents]]
---
This page is auto-translated from [/nishio/2023-08-12 07:08](https://scrapbox.io/nishio/2023-08-12 07:08) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.