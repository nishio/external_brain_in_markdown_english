---
title: "Whose Opinions Do Language Models Reflect?"
---

LLMs [[RLHF]] will have higher income, higher education, and more liberal views
- Because those who disagree will not participate in the RLHF.
- Not returning Human Feedback to LLMs has the effect of disadvantaging the opinion group to which one belongs in the future.

> Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reflected by current LMs (e.g., 65+ and widowed individuals).
- [https://arxiv.org/abs/2303.17548](https://arxiv.org/abs/2303.17548)

(DeepL) language models (LMs), the opinions reflected by LMs in response to subjective queries not only have a significant impact on user satisfaction, but can also shape the opinions of society as a whole. In this study, we propose a framework for quantitatively investigating the opinions reflected by LMs by using high-quality public opinion polls and associated human responses. Using this framework, we created a new dataset, OpinionsQA, to assess the consistency of LM opinions with those of 60 demographic groups in the United States on topics ranging from abortion to automation. For each topic, we found that there is a significant discrepancy between the opinions reflected by the current LM and those of U.S. demographic groups, comparable to the conflict between Democrats and Republicans on climate change. Notably, this misalignment persists even after explicitly directing LMs to specific demographic groups. This analysis not only corroborates prior research on the left-leaning tendencies of LMs adjusted for human feedback, but also highlights groups (e.g., over-65s and widows) whose views are less likely to be reflected in the current LMs.

![image](https://gyazo.com/494da8d1ac100649e3db58eb894ff6fa/thumb/1000)


---
This page is auto-translated from [/nishio/Whose Opinions Do Language Models Reflect?](https://scrapbox.io/nishio/Whose Opinions Do Language Models Reflect?) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.