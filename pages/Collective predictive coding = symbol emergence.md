---
title: "Collective predictive coding = symbol emergence"
---

- [[collective predictive coding]] ＝ [[symbolic emergence (springing up from a seedbed, esp. as a result of an explosion of symbols)]]
- [[Collective]] / [[prediction]] / [[encoding]]
- [[Tadahiro Taniguchi]]
> [tanichu](https://twitter.com/tanichu/status/1762044721160155267) [[NEW]] Single Author, Japanese, Outlook Paper
>  "Cognitive Science," "Dynamics of Language and Cognition Based on Collective Predictive Encoding: Toward New Developments in Symbolic Emergence Robotics," [https://doi.org/10.11225/cs.2023.064...](https://doi.org/10.11225/cs.2023.064...)
>
>  It is like Taniguchi's current understanding of the world and his vision of it, written to the best of his ability alone.
>
>  ① Isn't [[language emergence]] a collective [[predictive encoding]]?
>  ② If "[[Language]]" is taken as the subject, humans come to a subordinate position ([[language-subordinated worldview]]).
>  If we consider "language" as a subject, language emergence is representation learning of [[external representation]].
>  Therefore, language emergence can be expressed as a [[generative model]].
>  ⑤ [[Language Games]] is a form of [[decentralized Bayesian inference]] algorithm.
>  ⑥ Therefore, it can be straightforwardly developed as AI and robotics research, including to the social level. ([[Socialization of the world model]])
>  ⑥ Linguistic emergence may therefore be seen as based on the [[free energy principle]] "in society".
>  ⑦ [[Large-scale language models]] internalize the structure of the results of the above-mentioned [[learning by group representation]], so they internalize the structural information of the world. Therefore, it "knows the world" unexpectedly in a way that integrates the human [[cyclic world]]. I think that a (predictive) encoding such as next token prediction is sufficient for this learning.
>
>  I am writing this based on this kind of world perception, although there are some meanings. Please have a look.
>
>  Also, in English, it is preprint, but
>  Taniguchi, T. (2023, August 15). Collective Predictive Coding Hypothesis: Symbol Emergence as Decentralized Bayesian Inference. [https://doi.org/10.31234/osf.io/d2ty6…](https://doi.org/10.31234/osf.io/d2ty6…)
>  I have written about collective predictive coding in > (UNDER REVIEW).
>
>  By the way, Mr. Ueda of Tokyo University
>  @CsWeddy
>  Lewis's Signaling Game as beta-VAE," which was accepted by ICLR2024, is a grounded formulation of language (symbol) emergence as such expressive learning and a discussion of the implications it brings.
>  [https://x.com/CsWeddy/status/1762044721160155267?s=20…](https://x.com/CsWeddy/status/1762044721160155267?s=20…)
>
>  We are also publishing a bird's eye view survey of language emergence at the same time, thank you.
>  [https://x.com/tanichu/status/1768427404261982241?s=20…](https://x.com/tanichu/status/1768427404261982241?s=20…)
>  ![image](https://pbs.twimg.com/media/GIq3gFGaAAAtt5C?format=png&name=medium#.png) ![image](https://pbs.twimg.com/media/GIq3l1dbcAACYBy?format=png&name=900x900#.png)

> [tanichu](https://twitter.com/tanichu/status/1768434030729724014) It is still a "vision" and needs to be supported and applied by many studies, but since it is a vision paper, I would be happy to give inspiration to many people and expand and deepen the discussion further. I would be happy if I could give inspirations to many people to further expand and deepen the discussion. ...
>  >:


---
This page is auto-translated from [/nishio/集合的予測符号化＝記号創発](https://scrapbox.io/nishio/集合的予測符号化＝記号創発) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.