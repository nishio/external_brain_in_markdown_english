---
title: "I don't know what you're talking about, but it's clever."
---

> [takahiroanno](https://x.com/takahiroanno/status/1884234015554822201) [[DeepSeek-R1]], make the thought processes spit out easy to understand for humans! The story of the [[Language Consistency Reward]] is very interesting!
>
>  I think it's the same with people. There are people [[who]] don't know what they're talking about, but they're very [[smart]].

> [sikinori](https://x.com/sikinori/status/1884236085389320272) I don't know what you're talking about, but how do I know you're smart?

> [nishio](https://x.com/nishio/status/1884321659320242425) This is an interesting question. Someone acts a certain way and we ask, "Why did you do it?" and the explanation makes no sense, but when I ask, "What happened as a result of that action?" and you ask, "How did you achieve that?" and the results are so spectacular that you don't know how to make it happen.
    - [[reason]] and [[results]]
- Before and After Action
        - [[Correctness of decision-making]]

> [hrjn](https://x.com/hrjn/status/1884364293178810846) I think I understand this intuitively. There is a lot of information that is lost the moment you put some kind of [[probability distribution]] or [[stochastic process]] into words, and even in the case of "simple explanation of difficult things" which is common in the human world, it is often impossible to reproduce the difficult things from simple explanations. And even in the case of "explaining difficult things simply," as is often the case in the human world, it may not be possible to reproduce difficult things from simple explanations.

> [nishio](https://x.com/nishio/status/1884408509288386856) I see what you mean about stochastic processes, and there is a mechanism in humans that produces a high-dimensional vector output for a high-dimensional vector input, and we can learn to use that. But the operating process of it is difficult to explain in language because we don't use language. Just like it is difficult to explain [[how to ride a bicycle]] in words.

After a while, I reread it and thought, "No, I don't understand how a 'stochastic process' could come up here," so I had o1 generate an explanation, but then I finally realized that I also "don't understand" the connection between "stochastic process" and "a mechanism that produces a high-dimensional vector output for a high-dimensional vector input".

<img src='https://scrapbox.io/api/pages/nishio-en/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
A stochastic process is a model of how the state changes stochastically in a certain state space (including higher dimensions). If the state is represented by a high-dimensional vector, the output (next state) is determined probabilistically from the input (current state) at each point in time, so it can be understood as a "stochastic repetition of mapping from a high-dimensional vector input to a high-dimensional vector output". In other words, "stochastic process" can be viewed as a chain of stochastic changes (input → output) in a high-dimensional vector space, and the two are related.

relevance
- [[Smart people can explain things clearly.]]

---
This page is auto-translated from [/nishio/何言ってるのかよくわからないけど賢い](https://scrapbox.io/nishio/何言ってるのかよくわからないけど賢い) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.