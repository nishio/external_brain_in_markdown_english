---
title: "Hirokazu Shirado - Cybernetic Humanity Seminar Series"
---

[https://www.youtube.com/watch?v=KzJfWuyw6SQ&list=PLX2JSSjQzxy0kHxEP30KS-YA7uI59hi5M&t=3s](https://www.youtube.com/watch?v=KzJfWuyw6SQ&list=PLX2JSSjQzxy0kHxEP30KS-YA7uI59hi5M&t=3s)
<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>
Experiment 1: Cooperative Games Research in Networks (Nature 2017)
- Experimental design:.
    - 20 participants on the network choose from 3 colors
    - Each participant must choose a color that is different from adjacent nodes
    - 3 bots introduced (17 human participants + 3 bots)
    - Need to resolve color clashes throughout in less than 5 minutes.
- BOT REQUIREMENTS:.
    - Behavioral Noise Levels: (dB)
        - 0% (fully rational)
        - 10% (slightly random)
        - 30% (more randomness)
    - Location on network: (1)
        - Center (most connections)
        - random
        - Peripheral (least connected)
- Main findings:.
    - Centrally placed bots with 10% noise are the most effective: the
        - Accelerate group problem solving
        - Increased randomness of central player
        - Reduced randomness of surrounding players
    - 0% noise (perfect bots) cannot escape from the locally optimal solution
    - 30% noise is too unstable to reach optimal solution

Experiment 2: Driving Coordination Experimental Study (PNAS 2023)
- Experimental design:.
    - Online participants remotely control physical robotic vehicles
    - A "game of chicken" situation where two cars face each other on a one-lane road.
    - 10 rounds of repeated experiments
    - Economic incentives (the faster you reach your goal, the higher the reward)
- Experimental conditions:.
    - Safety support systems:.
        - Manual operation (warning only)
        - automatic brake
        - Automatic Steering
        - Automatic Braking + Automatic Steering
    - Communication functions
        - Message function available ("Please go ahead", "Thank you")
        - No message function
- Detailed findings:.
    - Impact of Automatic Braking:.
        - Support human decision-making
        - Facilitates communication
        - Maintain mutually beneficial behavior
        - Preserve diversity of social preferences
    - Impact of automatic steering:.
        - Substitutes for human decision making
        - Suppresses communication
        - Reciprocity is lost.
        - Convergence of behavior in a self-serving direction (about 90% self-serving behavior)
- Supplemental Experimental Findings:.
    - Dramatic change in behavior patterns after introduction of automatic steering
    - Reciprocal behavior not restored after system removal
    - [[Breaking the norm]] suggests more than a temporary economic adjustment.

Theoretical Implications:.
- [[AI assistants]] have more impact than just technical assistance.
- Fundamental impact on [[social norms]] and [cooperative mechanisms
- Emergence of new forms of [human-machine hybrids
- [New Research Proposals on the Boundaries of the "Self

Practical implications:.
- Designing AI-assisted systems requires consideration of social impacts
- Importance of balancing technical efficiency and social norms
- Need for design that supports while preserving human agency

This study shows that the introduction of AI technology has profound effects not only on individual behavior, but also on social norms and cooperative mechanisms. In particular, it reveals the potential for significant changes in human social behavior patterns depending on the method of support.

---
This page is auto-translated from [/nishio/Hirokazu Shirado - Cybernetic Humanity Seminar Series](https://scrapbox.io/nishio/Hirokazu Shirado - Cybernetic Humanity Seminar Series) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.