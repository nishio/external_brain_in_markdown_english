---
title: "LLM Summer School Competition"
---

10/10 deadline
- The final exercise of [[Matsuo Lab Summer School 2023 Large-Scale Language Models]] was a competition in which participants competed against each other for the best score.
- Three types of tasks are offered in the mix
- Two of them are mechanically quantifiable tasks (five-choice quiz, long summaries) that create leaderboards
- Mutually evaluate the quality of the remaining generated tasks with their top finishers.

Participants tackle the same issues by asking questions and discussing on Slack
- This is so helpful, it's like my own trial and error times extended several times over.
- When the "[[Please provide an offload_folder]]" that other participants were getting stuck with appeared in my environment, I was able to quickly check and solve the problem by saying, "Oh, this is what was talked about in Slack.

Matsuo Lab's exercise environment, omnicampus, can use up to 8 GPUs with 24 GB.
- You get 50 credits to start with, and if you use eight of them, you'll spend eight credits in an hour.
    - I received an additional 75 GPU hours of GPU credit!
    - The additional target seems to be the 313 people who score above baseline in the competition of the exercise, which is a big deal!

---
This page is auto-translated from [/nishio/LLMサマースクールのコンペ](https://scrapbox.io/nishio/LLMサマースクールのコンペ). If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.