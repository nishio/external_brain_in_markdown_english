---
title: "Are Emergent Abilities of Large Language Models a Mirage?"
---

Argument that LLMs appear to "get smarter rapidly with increasing scale" simply because they use a non-linear measure of smartness, such as the percentage of correct answers, and that a measure such as the token edit distance shows that they are not getting smarter rapidly.
![image](https://gyazo.com/405cb26843247336fa3ee4b9046fecfa/thumb/1000)
- (DeepL) The claimed emergent ability evaporates when the indicators are changed. From left to right: mathematical model, 2-integer 2-digit multiplication task, 2-integer 4-digit addition task. Top: When performance is measured by a nonlinear metric (e.g., accuracy), the performance of the InstructGPT/GPT-3 family appears sharp and unpredictable at longer target lengths. Bottom: When performance is measured with a linear metric instead (e.g., token edit distance), the family shows smooth and predictable performance gains.

Nishio's Supplement
- ![image](https://gyazo.com/430921b29980726eee4ac1f7760031c8/thumb/1000)
- If the percentage of correct answers is used as a scale, it is multiplied by the threshold function, "100 points if the threshold is exceeded, 0 points if not".
- Even in a situation where the mean of a distribution of the same shape is smoothly increasing, the graph of performance will show the shape of the derivative of the distribution as it passes through its threshold function
- If the distribution is bell-shaped, the derivative will be an S-curve.
- So even if there is a rapid rise in the graph of performance, it could be the result of the nonlinear nature of the scale.

> Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due to the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities; (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.
[https://arxiv.org/abs/2304.15004](https://arxiv.org/abs/2304.15004)
(DeepL) Recent studies have argued that large-scale language models exhibit emergent capabilities that are not present in smaller-scale models, but are present in larger-scale models. There are two interesting aspects of emergent competence: the sharpness of the instantaneous transition from nonexistence to existence, and the unpredictability that emerges at seemingly unpredictable model scales. That is, when analyzing fixed model outputs for a particular task and model family, the emergent ability appears due to the researcher's choice of metric, rather than due to a fundamental change in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent capabilities, while linear or continuous metrics produce smooth, continuous, predictable changes in model performance. (1)Using the InstructGPT/GPT-3 family, we make, test, and confirm three predictions about the effect of metric selection on the task for which emergent capability is claimed. (2)In a meta-analysis of emergent capacity in BIG-Bench, we make, test, and confirm two predictions regarding metric selection.Through the three analyses, we find that claimed emergent capacity evaporates with different metrics and better statistics and is a fundamental property of scaling AI models We provide evidence that it may not be.

---
This page is auto-translated from [/nishio/Are Emergent Abilities of Large Language Models a Mirage?](https://scrapbox.io/nishio/Are Emergent Abilities of Large Language Models a Mirage?) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.