---
title: "The Symbol Grounding Problem has been solved. So what’s next?"
---

Steels, Luc. "The symbol grounding problem has been solved. So what’s next." Symbols and embodiment: Debates on meaning and cognition (2008): 223-244.
[PDF [https://d1wqtxts1xzle7.cloudfront.net/30820623/steels2008symbol-libre.pdf?1392123708=&response-content-disposition=inline%3B](https://d1wqtxts1xzle7.cloudfront.net/30820623/steels2008symbol-libre.pdf?1392123708=&response-content-disposition=inline%3B) +filename%3DThe_symbol_grounding_problem_has_been_so.pdf&Expires=1732857281&Signature=b7AlZSYaPUWjeO0gfWD6pivEvjTo-n~Dgc1 zHKcbmIRRgFKHF-fbxEPdbRRUgxgXKOAaIHV9d3n4ik-2bomPv2NkqfHwdAgr5HhnyEEepgAzdnG2Y49RCZAiBSUwOd9c8xdx4oFGNPPZHG-vhH9G9oFOoXK~tSil~ rgISYm74BQ2cQJ13CpuaxQwz-wsAzCTRXFeivmFZwUWMhQnb6sZPJpx2Uu5exoPiyiT-IS413Owm8V-r~xgLEY-aIF-mCg6KTPV-KeeNjVdKRyhx4oXMZCB4BmO9 bRoRSBruLvZLoJE2~dQKwZTqSDc2krC3KT28VdQ-3hU0V3AROdfGo8C3g__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA] maybe prepring
[PDF](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf)

<img src='https://scrapbox.io/api/pages/nishio-en/GPT5/icon' alt='GPT5.icon' height="19.5"/>
Roger, I will compact the main points of Luc Steels (2008) "The symbol grounding problem has been solved. So what's next?"

Overview (what chapter)
- Included in Symbols and Embodiment: Debates on Meaning and Cognition (OUP, 2008, pp. 223-244). Edited by de Vega, Glenberg, Graesser.([PhilPapers](https://philpapers.org/rec/STETSG?utm_source=chatgpt.com), [Academic Oxford [https://academic.](https://academic.) oup.com/book/26191?utm_source=chatgpt.com])
- Standpoint: In response to the issues raised by Searle (Chinese room) and Harnad (1990), we argue that the "groundwork has been resolved "** in an experimentally feasible form. The rationale is that in a language game experiment with a group of embodied agents, the perception-concept-symbol connection is autonomous and the communication success rate is objectively improved. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
"I now boldly state that the symbol grounding problem is solved ..." (Conclusion at the end of the chapter) ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))

What constitutes a "solution" (Steels' recipe)
1. embodiment
Assumes an artificial agent with autonomous energy/computational resources, body as an entity, and sensors/actuators. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf?utm_source=chatgpt.com))
2. source of meaning
The starting point of meaning is the distinction that is beneficial to the agent's task accomplishment ("usefulness in the environment and interaction"). ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
- Category generation
Autonomous learning of discriminative categories by methods such as creating regions in perceptual space with prototypes and RBFs. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
4. symbolization
Assigning word forms to categories and expanding vocabulary. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
5. alignment
Group interaction with repeated naming/guessing games converges vocabulary and categories in a self-organizing manner. Success rate (comprehension/transfer) increased (Figure 12.3). ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
6. objective indicators
The increase in the success rate of communication is a measurable achievement criterion (= functional validation, not philosophical intuition). ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))

Specific examples of experiments and background research
- **Collective learning on the subject of color domain (color)**: agents form color categories, assign words, and align in interaction; represented by BBS target paper (Steels & Belpaeme 2005). ([Cambridge University Press & Assessment [https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/coordinating-](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/coordinating-) perceptually-grounded-categories-through-language-a-case-study-for-colour/423FB60CE8E6BFB0ADC23FFD48FBD4F0?utm_source=chatgpt.com ], [PubMed](https://pubmed.ncbi.nlm.nih.gov/16209771/?utm_source=chatgpt.com))
    - [[Coordinating perceptually grounded categories through language: A case study for colour]]
- The subsequent "Grounded Naming Game" chapter emphasizes the integration of the semi-symbolic cycle (perception -> conceptualization -> language). ([martin-loetzsch.de](https://martin-loetzsch.de/publications/steels12grounded.pdf?utm_source=chatgpt.com))

Conceptual Organization (terminological points in this chapter)
- Semiotic ternary relation: symbol - object - concept + method (applicability determination procedure); "grounded" if method is valid. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
- Semiotic network: a large number of links between objects, symbols, concepts, and methods are dynamically updated by experience and become communication pathways. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
- A terminological arrangement that should separate "symbolic programming" from the semiotics of the mind. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))

What's Next?" (Steels' suggestion)
- Robot experiments in further semantic domains such as tense, modality, situation role, and action categorization,
- Tracking population dynamics (including large scale observations in the internet age). ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))

Discussion, Criticism and Limitations
- There is a persistent philosophical objection that it is unresolved (e.g., Bringsjord 2015 "remains unresolved"); Steels' "resolution" is in the engineering and functionalist sense and does not deal with consciousness or even the metaphysics of intrinsic orientation. ([Taylor & Francis Online](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2014.940139?utm_source=chatgpt.com))
- Review articles are also evaluated as "being unraveled in practice but challenges remain" (e.g. Cangelosi 2011). ([pearl.plymouth.ac.uk [https://pearl.plymouth.ac.uk/cgi/viewcontent.cgi?article=2817&context=secam-research&utm_source=chatgpt.com](https://pearl.plymouth.ac.uk/cgi/viewcontent.cgi?article=2817&context=secam-research&utm_source=chatgpt.com) ])
- The original formulation is Harnad (1990). See also also Foundations (bottom-up grounding in non-symbolic representations). ([cs.ox.ac.uk](https://www.cs.ox.ac.uk/activities/ieg/e-library/sources/harnad90_sgproblem.pdf?utm_source=chatgpt.com))

Reference links (where available)
- Chapter publication PDF (VUB): text and figures. ([Artificial Intelligence Lab Brussels](https://ai.vub.ac.be/sites/default/files/steels-08e.pdf))
- OUP version of chapter page: bibliographic information. ([Academic Oxford](https://academic.oup.com/book/26191/chapter/194318096?utm_source=chatgpt.com))
- BBS 2005 (representative study of color categories). ([Cambridge University Press & Assessment [https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/coordinating-](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/coordinating-) perceptually-grounded-categories-through-language-a-case-study-for-colour/423FB60CE8E6BFB0ADC23FFD48FBD4F0?utm_source=chatgpt.com ])
- Grounded Naming Game (a coherent commentary on later years). ([martin-loetzsch.de](https://martin-loetzsch.de/publications/steels12grounded.pdf?utm_source=chatgpt.com))
- Rebuttal: Bringsjord 2015.([Taylor & Francis Online](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2014.940139?utm_source=chatgpt.com))
If necessary, we will delve a little deeper into Figure 12.3 (Success Rates) and the mathematical and implementation essentials of the naming game.

What do you mean by "explainable by symbolic networks and their dynamic interactions"?<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>

<img src='https://scrapbox.io/api/pages/nishio-en/GPT5/icon' alt='GPT5.icon' height="19.5"/>
To put it bluntly--
The position is that meaning and word usage are explained not as a "fixed dictionary" but as a process of updating a network of nodes (symbols, concepts, perceptual features, and application procedures) and edges (associations and constraints) that interact with each other. As a result, comprehension, utterance, learning, and convention formation can be described causally on the same mechanism.

1) What is a symbolic network?
- Node type
    - Symbols (word forms and syntactic patterns)
    - Concepts/categories (prototypes and feature vectors)
    - Perceptual features (color, shape, position, etc.)
    - METHOD (a procedure to determine "is this concept applicable in the current situation?)
- Edges: association strength, application conditions, suppression relation, etc. (weighted).
E.g., "red" ↔ [[red category]] ↔ [[wavelength distribution]], "take out" ↔ [[removal event syntax]].

2) What is "dynamic interaction"?
The same network causes state transitions and weight updates for each application.
- Interpretation (I know it when I hear it)
    - Input word → activation diffuses to the conceptual or perceptual side → method evaluates applicability → conflicts are resolved by inhibition.
    - Formula image: $\arg\max_c ; w(\text{word},c)\cdot \text{applicability}_c(\text{context})$
- Produced (say what you mean)
    - Return activation from the concept to the word form to be conveyed and select words that have the highest probability of success.
    - $\arg\max_w ; w(c,\text{word})$
- Learning (updating from mistakes)
    - If successful, strengthen the bond; if unsuccessful, weaken or repair (subdivide categories, invent/adopt new terms, add usage constraints).
    - Example: $w \leftarrow w + \alpha(1-w)] / [$ w \leftarrow (1-\beta)w$
- Alignment (collective convergence)
    - Iterations of naming games, etc., each individual's network draws on the other, and vocabulary and boundaries converge (convention = macro stable state = attractor).

3) What makes something "explainable"?
In this framework, the following can be explained and predicted by the same model.
1. comprehension rate and success rate of transmission (why learning raises the rate)
2. polysemy/ambiguity behavior (activation and suppression of competing paths)
3. semantic change and differentiation of words (a consequence of repair operations and environmental adaptation)
4. lexical invention and expansion (process of creating new categories → assigning symbols)
5. social convergence (why shared conventions emerge in interactions)
→ By this I do not mean "because the dictionary says so", but rather that the dynamics of network states x interactions allows us to speak consistently and causally from intra-individual (micro) to collective (macro).

4) Difference from static symbol table (contrast)
- Static table: word ⇄ meaning is assumed with a fixed mapping. Displacement, learning and change can only be treated as external factors.
- Dynamic net: Displacement, learning, change, and convergence itself can be described as internal phenomena of the model (update law).

5) Very mini example (color words)
1. initial: weak association "red"-red, coarse color category.
- Failure: opponent pointed to another red area → split category or adjust word boundary.
3. success: reinforcement in the relevant case → more weight, next time it will pass without hesitation.
4. group iteration: convergence to the same boundary/word in many-person interaction (convention).

6) The scope of "solution" here
- This position deals with functional grounding (the connection of senses-concepts-symbols in a way that is conducive to task success).
- Although it does not extend to metaphysical issues such as conscious qualia, I would argue that it is "explainable" in that "why we know/pass/change" can be described by the same dynamics.
- If necessary, a simple simulation pseudo code using this network and the design of the update law (reinforcement, side suppression, and conditional branching for invention, adoption, and repair) are also shown.


<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>
This paper develops an important discussion of the "[[symbol grounding problem]]" ([[symbol grounding problem]]) by [[Luc Steels]]. The main points are as follows:

- The Nature of the Symbol Grounding Problem
    - The question of whether artificial intelligence systems can autonomously generate meaning and connect symbols to the world
    - Can the system itself establish meaning rather than mere programming or human design?

- Organizing Key Concepts
    - Distinction between "[[symbol]]" in computer science and "symbol" in cognitive science
        - Organize the concept of symbols (symbols)
            - Symbols in Computer Science (c-symbols):.
                - Technical concepts in programming languages
                - Pointer (address) in memory
                - Implementation concepts for data structure and memory management
                - Technical components used in symbolic processing languages such as LISP
            - Symbols in cognitive science (m-symbols)
                - Concepts as symbols with meaning
                - Connected to objects and concepts in the world.
                - Social commitments and cultural context.
                - Play a semantic role in communication and cognition

    - [Different interpretations of [representation
        - Organizing the concept of representation
            - Traditional notions of representation:.
                - Something that serves as a "substitute" for something else.
                - Includes meanings and perspectives
                - Requires interpretation and reasoning
                - context-sensitive
            - Representation (c-representation) in computer science:.
                - Data structures for computational processing
                - Technical mechanisms for information retention and manipulation
                - There are symbolic and non-symbolic representations (e.g., analog values)
                - Used as an implementation concept

        - The plural meaning of [[corporeality]] ([[embodiment]])
        - Conceptualization of Embodiment
            - Embodiment as Implementation:.
                - Physical realization of ideas and methods
                - Specific implementation methods of the system
                - Possibility of implementation on different physical media
                - Embodiment from a technical perspective
            - Embodiment as physical body:.
                - Having an actual physical body.
                - Interact with the world through sensors and actuators
                - Physical relationship with the environment
                - The Body as an Entity in Robotics

- Approaches to Solution
    - Use of physically embodied autonomous agents
    - Mechanism that allows agents to generate their own meaning
    - Self-organization of symbols
    - Coordination process among agents

- Verification by experiment
    - Language game experiment using a robot
    - Experiments on color recognition and naming
    - Demonstration that agents can autonomously generate and adjust meanings and symbols

- Conclusion.
    - Claims that the symbol grounding issue has basically been resolved.
    - Explainable by symbolic networks and their dynamic interactions, not by biological matter
    - Further experiments, neural correlates studies, and psychological observations are needed in the future.

This paper is an important contribution that offers a concrete solution to one of the key philosophical problems in artificial intelligence research.

<img src='https://scrapbox.io/api/pages/nishio-en/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
Implications for human intellectual productivity from this study include the following

- [[Dynamic Generation of Meaning]] and Sharing: Meanings and categories are not defined by fixed definitions, but are formed and adapted in a self-organized manner through collaboration and dialogue. Understanding this process helps humans to quickly share and establish new concepts and terms, and to develop smooth communication strategies that increase productivity.

- [Knowledge emergence through social interaction: Just as interactions between agents nurture meaning systems, the accumulation of discussion, information sharing, and trial and error in human groups encourages the emergence of new ideas and intellectual outcomes. By effectively designing and utilizing group work and online collaborative tools, we can build a knowledge creation environment that enhances productivity.

- [[Adaptive category formation to the environment]]: Flexibly recombining concepts and categories to fit the surrounding situation and task requirements supports problem solving and creative thinking. Mechanisms that encourage adaptive concept formation in education, training, and knowledge management systems at the individual and organizational levels will lead to more efficient idea generation and decision making.

Overall, the findings of this study provide clues to reassessing communication and knowledge formation in human society as a dynamic, collaborative, and flexible process, and to improving that process to increase intellectual productivity.

---
This page is auto-translated from [/nishio/The Symbol Grounding Problem has been solved. So what’s next?](https://scrapbox.io/nishio/The Symbol Grounding Problem has been solved. So what’s next?) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.