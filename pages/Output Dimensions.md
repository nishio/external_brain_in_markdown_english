---
title: "Output Dimensions"
---

2018-05-02
![image](https://gyazo.com/e1923c124bc1abcd896f8c10fa5cf521/thumb/1000)

- Methods of representation in two dimensions embed higher-order information in the brain into lower dimensions
    - word2vec, for example, embeds the meaning of a word in a vector of several hundred dimensions.
    - It would be in that higher state of the brain.
- It is fragmented and output by using the writing out method.
- In the KJ method,
    - First lay out what you wrote down.
        - This is to force information to be embedded in a two-dimensional form that is easy for humans to observe and manipulate
    - Next, we change the position so that the distance is well preserved in the higher dimensional space in the brain
        - This is the group formation.
        - Since it is moved while keeping the constraint that it is placed on a two-dimensional space, it remains two-dimensional.
    - Bundle cards to have multiple different "[[detail level]]" ref. [[KJ method is pseudo-3D]].
            - In the era when the [[KJ method]] was created, there was no way to have multiple [[details]] and store or distribute them.
                - [[Multiple levels of detail at different]]

- Written expression is embedded in one dimension
        - [[One-dimensional text]]
- When people say that bullet points are two-dimensional, I feel that they are talking about something less dimensional.  [[Bullet points are not two-dimensional.]]
- Bullet points are more flexible in structure than spoken utterances
    - but it is the same kind of comparison between a one-dimensional array and a tree
    - No denial of a more expressive structure.
        - Same as [Sapir-Whorf hypothesis
        - Human thought is influenced by the expressive power of language as the tool he uses.
        - Example in a programming language: ...
            - People who have no experience with languages with higher-order functions have difficulty coming up with abstractions that pass functions as arguments.

[[2018-05-02]]

---
This page is auto-translated from [/nishio/出力の次元](https://scrapbox.io/nishio/出力の次元) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.