---
title: "Moderate size to be left to AI"
---

> [nishio](https://x.com/nishio/status/1891309951600975915) The larger the size x of the task entrusted to the [[AI Agent]], the lower [[human work frequency]]1/x becomes, but the probability p^x of succeeding x consecutive times in a task that succeeds with probability p also decreases. is utility, and utility reaches a maximum value at a reasonable size to be entrusted to AI.
>  ![image](https://pbs.twimg.com/media/Gj9IDFNagAAuC9v?format=png&name=900x900#.png)

p=0.75
![image](https://gyazo.com/a9a487edffecbcc86a194f22ebae342c/thumb/1000)

A larger x is optimal because CI and static type testing makes p better. x=1 in the case of ChatGPT and turn-based communication, and people who hear that "AI agents will proceed automatically" as a quick observation of the world tend to ask for x=10 or so, and when they do so, they find that they are not as effective as they thought they were. It is not as effective as it could be.

p=0.99
![image](https://gyazo.com/58d8b92c73db83c6409aff0d7ac19795/thumb/1000)
- As the success rate increases, the maxima gradually move to the right.

After writing all this, I realized I forgot an important factor: the financial burden of running an AI costs about x^(1~2)w
- Subtracting that, the maxima move to the left.
    - This has to be compared in terms of human cost and AI cost.

---
This page is auto-translated from [/nishio/AIに任せる適度なサイズ](https://scrapbox.io/nishio/AIに任せる適度なサイズ) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.