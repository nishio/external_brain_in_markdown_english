---
title: "Can LLMs Design Good Questions Based on Context?"
---

[https://arxiv.org/abs/2501.03491](https://arxiv.org/abs/2501.03491)

[https://x.com/omarsar0/status/1877008618207560049](https://x.com/omarsar0/status/1877008618207560049)
>  There is a strong preference for asking about specific facts and figures in both LLaMA and GPT models.
>  In both the LLaMA and GPT models, there is a strong need to ask about specific facts and figures.
>  The question lengths tend to be around 20 words but different LLMs tend to exhibit distinct preferences for length.
>  Questions tend to be about 20 words in length, but different <code id=g1001>LLMs tend to show a clear preference for length.
>  LLM-generated questions typically require significantly longer answers.
>  Questions generated by LLM usually require fairly lengthy answers.
>  Human-generated questions tend to concentrate on the beginning of the context while LLM-generated questions exhibit a more balanced distribution, with a slight decrease in focus at both ends.
>  Human-generated questions tend to be concentrated at the beginning of the context, while LLM-generated questions show a more balanced distribution, with slightly less focus at both ends.

The questions generated by the LLM are not universal in terms of where they are asked.

---
This page is auto-translated from [/nishio/Can LLMs Design Good Questions Based on Context?](https://scrapbox.io/nishio/Can LLMs Design Good Questions Based on Context?) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.