---
title: "Grokking"
---

> [hillbig](https://twitter.com/hillbig/status/1762624222260846993/history) Grokking, which improves generalization performance when training continues even after the training error reaches 0 in NN, is due to a phase transition that occurs when the nonlinear region (black line in the video) moves to the classification Grokking is a phenomenon that occurs when the nonlinear region (black line in the video) moves to the classification plane and the region around the sample is linearized (robust to hostile perturbations). The video visualization is amazing [https://arxiv.org/abs/2402.15555youtube.com](https://arxiv.org/abs/2402.15555youtube.com)
>  Grokking Visualized for MLP trained on MNIST
>  Supplementary Video for paper:Grokking Happens All the Time and Here is Whybit.ly/grok-adversarialWe train a 4 layer MLP with 256 width, on 1000 training sam...

I see
before
![image](https://gyazo.com/ca9d58db23682619d2e208ea46d205ba/thumb/1000)
after
![image](https://gyazo.com/6e808ae2a6b3f3f9188e25d1b2d3b6a0/thumb/1000)


---
This page is auto-translated from [/nishio/Grokking](https://scrapbox.io/nishio/Grokking) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.