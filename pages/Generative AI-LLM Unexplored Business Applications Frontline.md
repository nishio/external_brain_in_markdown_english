---
title: "Generative AI/LLM Unexplored Business Applications Frontline"
---

With AI's assistance, the article was adapted from a video of the panel discussion.
- I'll finish the conversation part ✅.
- The individual lecture portion would be too long to do in full, so I'll leave it here in summary ✅.
    - Details to be developed on a separate page? (pending)

<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>This is a summary of the panel discussion titled "Frontiers of Generative AI/LLM Unexplored Business Applications" held as a special event of the Unexplored Conference 2024.

The four panelists are as follows
- Shohei Hito, Chief Engineer, Technology Innovation Center, Daikin Industries, Ltd [/mitou-meikan/Hito Shohei](https://scrapbox.io/mitou-meikan/Hito Shohei).
- Mr. Shinta Nakayama (handle: Tokiten), President of NextInt Corporation [/mitou-meikan/Kinta Nakayama](https://scrapbox.io/mitou-meikan/Kinta Nakayama).
- Mr. Tatsuya Nakamura, Executive Officer and General Manager of AI/LLM Business Division, LayerX Corporation [/mitou-meikan/tatsuya-nakamura](https://scrapbox.io/mitou-meikan/tatsuya-nakamura).
- moderator
    - President and Representative Director, Sakura Internet, Inc.
    - Kunihiro Tanaka, Project Manager, Unexplored IT Human Resources Discovery and Development Project [/mitou-meikan/kunihiro-tanaka](https://scrapbox.io/mitou-meikan/kunihiro-tanaka).

First, Mr. Nakayama explained how recent generative AI is changing white-collar jobs. He said that jobs with indefinite inputs and outputs where mistakes are tolerated have been the domain of humans until the end, but that generative AI is replacing them. He pointed out that people with domain knowledge who can define requirements will be important in the future.

Mr. Hido then introduced examples of AI and LLM applications at Daikin Industries. He said that they are developing a work support system using first-person video of workers captured by wearable cameras. He also mentioned that LLM like ChatGPT is beginning to be used in the engineering department.

Mr. Nakamura spoke about the LLM business at LayerX, noting that the advent of LLM has eased the need for standardization in DX. He stated that LLM's strength can be demonstrated in the area of industry-specific and specialized document processing. He revealed that he is focusing on data preprocessing and business applications rather than the development of the underlying model.

The panelists pointed out the importance of not only standardization of operations but also organizational measures such as review capabilities and clarification of responsibilities in utilizing LLM. In closing, Mr. Nakayama's message to the young people was to look back at the past to predict the future, Mr. Hido's message was to value free thinking without being influenced by trends, and Mr. Nakamura's message was to use the time to steadily confront LLM.


[https://www.youtube.com/watch?v=MJPg4eyicQY&t=13190s](https://www.youtube.com/watch?v=MJPg4eyicQY&t=13190s)

# 本編
<img src='https://scrapbox.io/api/pages/nishio-en/gpt/icon' alt='gpt.icon' height="19.5"/><img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>
- (GPT Builder is used to create GPTs to clean up machine transcribed text, and Nishio reviews the output.)

# self introduction
.
Tanaka: Yes, thank you all for coming to our session. I would like to present "The Frontiers of Generative AI/LLM Unexplored Business Applications. My name is Tanaka, and I will be moderating this session. Thank you very much for your kind attention. I myself am a representative of Sakura Internet, which I started as a student 28 years ago, and since 2018, I have also been a project manager of the Unexplored Talent Discovery and Development Project. In my day job, I run a data center and provide GPU cloud and government cloud services. At the moment, we are offering NVIDIA's fairly fast GPGPU called H100. I would now like to introduce our panelists. Please go to the next page.

## Mr. Nakayama

Nakayama: Yes, my name is Shinta Nakayama. I go by @[[tokoroten]] on the Internet because it is written "heart-thick" and reads "tokoroten". As my day job, I run a company called NextInt Inc. Last year, I wrote a book called "[[ChatGPT Strategy]]," so I guess I'm called here. Recently, I've been working on an instructional book for adults on [[Information I]], which is done by high school students. As for my current work, I write code as a machine learning consultant and programmer, and I have been given corporate training at several companies. The materials I brought with me are basically excerpts from the training materials I provide to my clients.

Tanaka: You are famous for your distinctive Twitter icon.

Nakayama: When you create a company, you have to sell your name to get work, so I cut out some of my training materials and made them public in order to raise my profile and get work.

Tanaka: You were also at the top of the ranking of speakers.

Nakayama: Yes, you are called the number one instructor in one training service.

## Mr. Hido

Tanaka: Next, Mr. Hido, please.

Shohei Hido: Yes, my name is Shohei Hido. My involvement with Mittochi began in 2002, when I was selected as a co-recipient for the first year of the "Mittochi Youth" program, and since then I have been consistently working on industrial applications of machine learning for about 15 years at [[IBM]] and [[Preferred Networks]]. Now I am the chief engineer in charge of DX promotion at [[Daikin]] Industries. In short, I am working on industrial applications of AI technology as a tech lead in charge of AI technology. I would be happy to talk with you about that as well. Thank you very much for your time.

Tanaka: This is quite an exciting career change from Preferred to Daikin.

Hido: When I changed jobs from Preferred Networks to Daikin Industries, I thought that if I were to change jobs, I would prefer to work for an operating company, so I visited various operating companies when I started my job search.

Tanaka: I see. Internet companies tend to do business only on the Internet, but I think real growth can be expected by combining existing businesses with Internet and IT digital technologies. But the bottleneck was human resources. When this kind of job change occurs, I think it is great for manufacturers with existing strengths. Among them, Daikin is still very strong.

Hido: That's right. Daikin has a unique corporate culture, and we are allowed to do whatever we want.

## Mr. Nakamura

Tanaka: Thank you very much. Now, Mr. Nakamura, please give us your best wishes.

Nakamura: Yes, I am Nakamura from [[LayerX]]. It is a pleasure to meet you. I joined Unexplored in 2020, so I feel like you are my seniors. At the time, I was working on [[Ethereum]], a blockchain security project, as well as research on building Ethereum itself. Then, the theme changed, and now, as the business manager, I am conducting research on data security and privacy, and providing it to enterprise companies. I believe that LLM is important from the perspective of data utilization by enterprise companies, and I am developing products that utilize LLM.

Tanaka: What made you choose this career path of going to LayerX?

Nakamura: I have participated in LayerX since its inception, and then I joined Unexplored. I am a graduate of Prof. Matsuo's department, but I was a little bit naive when I saw that everyone was doing machine learning, so I became more interested in blockchain than in machine learning.
- [/mitou-meikan/Yutaka Matsuo](https://scrapbox.io/mitou-meikan/Yutaka Matsuo).

Tanaka: I wonder if LayerX is a good match for you, since you come from an unexplored background as a business owner.

Nakamura: Fukushima, the CEO of LayerX, founded Gunosy in 2012 before moving to LayerX. The management team is made up of members who love technology to the extent that they are not very logical.
- [/mitou-meikan/ Yoshinori Fukushima](https://scrapbox.io/mitou-meikan/ Yoshinori Fukushima).

# Case Studies
.
Mr. Tanaka: I'd like to start by introducing a case study.

## Mr. Nakayama

summary<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>
- ![image](https://gyazo.com/c5508e5f0840a7e80985362804fe7cdd/thumb/1000)
    - A graph with error tolerance on the horizontal axis and input/output complexity on the vertical axis can be used to organize various types of work.
    - Problems that can be solved by programming are limited to areas where inputs and outputs are routine and errors are unacceptable.
    - Many white-collar workers have complex jobs where inputs and outputs are irregular and mistakes are tolerable.
    - Lawyers and accountants have a job where the inputs and outputs are extremely complex, but there's no room for error.
    - Machine learning is replacing routine jobs that can go wrong.
    - With the advent of generative AI, jobs with irregular inputs and outputs are being replaced by AI.
    - Skills to transform problems so that "mistakes are acceptable" are critical in the machine learning era.
    - Generative AI will be able to perform requirements-defined tasks, increasing the value of those who can prompt-engineer domain knowledge
- It is thought-provoking to point out that the key to automating white-collar tasks with AI is to identify the nature of the task and apply appropriate AI technology, as well as the ability to verbalize domain knowledge and utilize AI. This is a helpful perspective on the future development of AI and the changing role of white-collar workers. In the long term, we may see a shift in the division of roles, with AI being entrusted with tasks while humans focus on higher-level work.<img src='https://scrapbox.io/api/pages/nishio-en/Claude/icon' alt='Claude.icon' height="19.5"/>
- [[誤りを許容できるプロセス]]に変換するスキルが重要なわけね<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>

### 議論
<img src='https://scrapbox.io/api/pages/nishio-en/gpt/icon' alt='gpt.icon' height="19.5"/>
Tanaka: By the way, I would like to ask a question. There is a current shortage of AI personnel, and there is talk of the need to train people in the sciences in order to create AI personnel. How does the idea that white-collar workers can solve problems if they are able to promptly solve them fit in with the idea that science-related personnel are needed and that AI personnel are needed?

Nakayama: Yes, when I talk about this in my training, I always say that people should learn "[[Science Writing Techniques]]" after this. When I talk about this in my training, I always say that they should learn "[[Science Writing Techniques]]" after that. If you can feed that kind of writing to LLM, you will get good results. Those who don't, write their feelings first, so the LLM tries to process their feelings and doesn't get good results. The skill is to be able to write facts properly as facts. As to whether we need science people or not, we absolutely need them. What kind of science-related personnel it is, we want people who can write science-related sentences properly.

Tanaka: I see. In training programs for working people, we often encourage them to acquire [[logical thinking]] or [[critical thinking]], in other words, the ability to organize information.

Nakayama: Yes, that's right. I don't want to divide people into science and humanities, but I think a science-oriented person is one who can think logically, and before that, can separate facts and feelings, what is possible and what is impossible, what is real and what is in his or her mind.

Tanaka: I see. So these are the people who will improve AI and become the gateway personnel to actually utilize generative AI. Thank you very much. We are actually trying to reduce the amount of work with generative AI, but I think it is important to note that inappropriate input may lead to different results instead of reducing the amount of work. Thank you very much.

## Mr. Hido
Hido: Now that Mr. Nakayama has organized the abstract framework, I would like to talk about the specifics.
![image](https://gyazo.com/f8efae14d82cd8915d70706c1593950f/thumb/1000)

summary<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>
- The use of AI in the [[OT]] ([[Operational Technology]]) domain is the new frontier.
        - Digitalization of [[blue-collar worker]] field work is important.
    - [[Thinklet]] wearable camera collects video data on workers
    - Aiming to use image recognition AI to analyze and support work
        - Project in progress with [[fairydevices]], Inc.
- We are also promoting the use of LLM (Large Language Model)
    - Company-wide environment for utilizing ChatGPT within the company has already been deployed.
    - Technology Innovation Center plans cutting-edge utilization
    - Especially in the design development, which is the main focus of the manufacturing industry, the use of AI for language and image generation is being verified.
- I believe that the fusion of OT and digital technology, or so-called IT/OT convergence, is one of the major directions of the manufacturing industry in the future. The key to success will be how to collect such real data from the shop floor and turn it into value using AI.
- On the other hand, generative AI has great potential for the advancement of knowledge work such as design development. The extension to multiple modalities such as drawings as well as language is an important issue.

### 議論
<img src='https://scrapbox.io/api/pages/nishio-en/gpt/icon' alt='gpt.icon' height="19.5"/>
Tanaka: At the Fairy Devices booth in the back, you can actually put on the device and experience the first-person perspective. I actually had a chance to experience it just a few minutes ago. I would like you to see the value of being able to remotely fly images that people are watching.

Tanaka: In the manufacturing industry, especially in advanced AI countries such as the U.S., labor unions sometimes oppose the use of AI because it takes away people's jobs. In fact, that is why many startups have moved to Japan. In the case of your headquarters, how do you actually perceive the reaction of the people around you to the utilization of AI, whether it is negative or positive?

Hido: Yes, that's right. In fact, we are rather short of manpower. It is said that Daikin's business and the air conditioning market as a whole will continue to grow rapidly, and by 2050, compared to the situation in 2015, the market will be three times larger than before. This is because there are still regions such as Africa and India where air conditioning equipment has not yet fully entered the market. So Daikin and other air conditioning manufacturers are trying to increase their production capacity by setting up factories around the world, and the situation is such that there is actually demand. We don't have enough people who can install the equipment to connect between them. As well as maintenance, there are still tasks that need to be done by humans. Even in Japan, people who are not qualified as construction workers cannot install air conditioning equipment, so for example, if you call someone in August and say your air conditioner is broken, they will not come right away; they will have to wait. Digital and AI technologies are very effective in how to solve such labor shortages and improve work efficiency. Daikin is also actively investing in this area.

Tanaka: Yes, thank you very much. There is a labor shortage all over the world, but in Japan in particular [[aging population combined with the diminishing number of children]], you can't help but feel it. It is generally said that because there is not enough manpower, there is little resistance to the arrival of AI, and I think it is very suggestive that such a situation exists at Daikin as well.

Tanaka: What I wanted to ask you is that I think Daikin invests quite a bit in research and development. I think other manufacturers should do more of that, but I think Daikin is also very advanced in its use of advanced technology.

Hido: Well, it is difficult to criticize other companies, but Daikin is characterized by a lack of human resources to utilize AI, as opposed to the lack of human resources as field workers that I mentioned earlier. I think it is difficult to hire talented people in the information field because they go to IT companies. In 2017, Daikin launched [[Daikin Information Technology University]] within the company, an ambitious initiative to train 100 new employees in AI and other digital technologies for two years, during which time they will not be assigned to a business unit. This spring, a cumulative total of 450 people have been gathered, and these people have been assigned to business divisions to promote AI applications. Daikin was quick to move in this area, and I believe that the top management's decision to train personnel in this way is now paying off.

Tanaka: Well, thank you very much. I think this story is appropriate to understand that human resource development is very important.

## Mr. Nakamura
![image](https://gyazo.com/758ea79e70b94d71744962591a47c1d6/thumb/1000)
summary<img src='https://scrapbox.io/api/pages/nishio-en/claude/icon' alt='claude.icon' height="19.5"/>
- The advent of LLM has eased the need for standardization of work in DX, allowing systemization as long as it is in place to the point where it can be directed to LLM.
- ![image](https://gyazo.com/b58b1d4bb0e87c11d7b183930a5d78de/thumb/1000)
- LLM is particularly adept at reading long sentences and putting them into the same format. This makes it easier to handle financial statements and contracts written in natural language.
- Currently developing a product that will read, store, and utilize long-form text.
- ![image](https://gyazo.com/b407322aaf21ea75be97232a5ebc4f8e/thumb/1000)
- We believe there is value in applying LLM to niche and professional operations. There is room for innovation through LLM in operations where the market size is small.
- The power of LLM has enabled amateurs to provide good algorithms in a short period of time, even in highly specialized fields.
- Rather than looking for use cases that are unique to LLM, we are focusing on traditional use cases that can be made overwhelmingly more efficient by LLM.
- There are also examples of specific initiatives, such as the review of insurance documents and their application to financial contracts.
- LLM is not yet the "killer app" for everyone at this time. Tuning and customization to niche operations is essential.
- With proper tuning, LLM accuracy can be increased from 50% to 80-90%.
- How LLM is integrated into operations is the key to whether LLM can truly transform operations in the future.
- The talk was rich in suggestions about the possibilities of LLM and recognition of issues for actual business application. I was particularly impressed by his focus on breakthroughs in highly specialized, individual operations, and the development of LLM.


Tanaka: Thank you very much.

NAKAMURA: Right now, our policy is to not create a foundation model at all, quite intentionally.

Tanaka: I see. So you are using GPT-4 or something that is provided by an existing cloud vendor?

Nakamura: Yes, that's right. The reason is that when we look for use cases for LLM, we try to prioritize those that have a clear correct answer and a clear process to get to the correct answer. As long as we target such use cases, I feel that there is less chance of problems due to the underlying model. If anything, I would rather apply R&D resources to improving file preprocessing and searching before entering LLM.

Tanaka: I see, the UX is very good, not only the UI, but also the R&D of the in-out parts, such as the ability to send PDF files as is, is that a strategic decision?

NAKAMURA: That's right. I believe that the market is too small for only use cases where human operations can be handled by AI from beginning to end. It would be better to have AI handle only a part of the business, or to have the business slightly changed to use AI, or to change the business to be handled through a different route, in order to expand the range of application and the market. We would like to provide support for changing business operations as well.

Tanaka: I see, thank you. I think that's very thought-provoking. LLM development tends to get a lot of attention these days, but in fact, there is an argument that creating a lot of LLMs is not "reinventing the wheel. Of course, the LLM development side may be important, but I think you have talked about the importance of improving the UX and actually changing the customer's business. Thank you very much.

# Utilization issues
.

Mr. Tanaka: I would like to get into the utilization issues here. I would like to be introduced by Mr. Nakayama.

## Mr. Nakayama
- ![image](https://gyazo.com/17f0468832c64c04997f3bbf7e5526dc/thumb/1000)
- Work can be divided into two main types: "work" and "review.
- With the assistance of generative AI, the task itself becomes easier.
- On the other hand, reviews will not be easy, and it will take a commensurate amount of study and skill to properly evaluate the AI's output of results.
- ![image](https://gyazo.com/97145d4fb8fd09b0ab070c87877f53b8/thumb/1000)
- The smarter AI gets, the more people it can work with, but the more people it can review will become scarce and scarce.
- From now on, it will be important to be able to be on the side of those who can review.

Tanaka: Yes, thank you. It is really important to be able to review. I also ask ChatGPT to write an email, but in the end I have to review the whole thing. If it was just an email, though, everyone would review it. I wonder if ChatGPT will eventually understand the correspondence between Dear Sir or Madam to that extent.

Nakayama: I think at least Dear Sir or Madam, it will probably be fixed in time, but that said, I think it will be another 5 or 10 years before ChatGPT will no longer require reviews.

Tanaka: I see. In the meantime, I don't know if it's a good thing or a bad thing that human jobs are not going away.

Nakayama: Hmmm, I think there is a point where it is difficult, because that is the story that "jobs for high level people will not disappear".

Tanaka: Yes, thank you. Mr. Hido, may I ask you a favor?

## Mr. Hido

![image](https://gyazo.com/19c8102c135968be3a01a4c5c4487054/thumb/1000)

Hido: Actually, when I saw the slides earlier in the rehearsal stage, there was a part of me that thought they were a little different from my ideas. I didn't say anything because I thought it would be better to have a discussion on this anyway. Even in the review, there is a division between the work of checking against it and picking out what is wrong here, and where the human being is ultimately responsible for the work. I think we could use the AI's assistance in picking out the points that need to be reviewed and the points that are questionable.

Nakayama: Yes, we can assist in the review process, but I think the clear point is where we ultimately take responsibility for that. After all, if we miss something, it is the responsibility of the person who missed it, and even if the AI comes up with a list saying, "Maybe something is wrong here," we also have to take responsibility for the parts that are not on the list.

Hido: When automation is implemented, we need to look at whether the miss rate is within the acceptable range, whether it is within the acceptable level, and how much it will lead to increased efficiency. I think there are still many areas where this is insufficient.

Nakayama: Yes, that's right.

![image](https://gyazo.com/c43f288866b20091bf0c0422c2926236/thumb/1000)

Hido: I wanted to talk a little bit about the current point, but in the abstract, ChatGPT and GPT-4 were good in the short term for about a year, but now that Anthropic's Claude 3, which came out last week, is even better, everyone is talking about whether we should switch to that. This is a short-term discussion. I think this is a short-term situation, and in the future, users will have a variety of options to choose from. I am not so pessimistic about this, or rather, I don't see it as a problem. I think the hot issue for utilization in the short term is how to secure things like [[Continuous Integration]] and [[Continuous Delivery]] in combination with generative AI.
- What I want to emphasize is a little more mid to long term, like ChatGPT changed from GPT-3.5 to GPT4, and then Claude 3 came out, and soon GPT-4.5 and GPT5 will come out, and they will be smarter than Claude 3, so on a 6-month and 1-year level, like in humans. It's like from elementary school to high school, from high school to doctoral level of intelligence.
- In this situation, when your work becomes most important, for example, for me, when I think that in three or five years when the service support using video images that we are collecting at Daikin service sites will be put to practical use, a smarter generative AI will be available, it is important how to prepare the data to make the best use of it. If we start collecting data after we know it is possible, it will take roughly one or two years from there, so we need to predict the evolution of the smartness of the generative model now, and collect data in our own organization that we can use when that time comes.
- That kind of project is tough, because collecting them now doesn't create value, so people tend to say, "What's the point of that?" How do you overcome this and make an investment decision? How to overcome this and be able to say, "This will create value in the future, so let's collect it" as an investment decision will become an issue for various organizations. If we fail to do so, we will find ourselves in a situation where we have a good model but have no way to use it, because we have no data. What I would like to recommend to everyone is to anticipate such a trend and convince the top management that "this is why we have to collect this kind of data from now on, and we have to pay the cost for it" before proceeding. I think this is important.

Tanaka: Thank you very much. By the way, in terms of data, there will naturally be data that increases on a time axis, but I think GPT-4 has covered most of the data that can be searched on the Internet at this time. So, even if data increases in the future, it will only be in the form of time-series data. But the data that can be searched worldwide is only a part of the data that has been created, and most of it is not searchable on the Internet. For example, you mentioned earlier what would happen if AI were introduced to the design and development process. What exactly do you expect the data you mentioned earlier to be?

Hido: To put it plainly, it's like the video I mentioned earlier of an air conditioner being repaired. It is questionable whether Google or OpenAI will learn from videos published on the Internet and come up with a generative AI that fully understands how to fix air conditioners without Daikin having to do anything anymore. Even now, if you search YouTube, you can find videos by air conditioning contractors saying, "You can fix it yourself this way," but at best they are on the order of 100 hours or 1,000 hours. In contrast, if we, as manufacturers, distribute and collect devices, we can collect 10,000 or 100,000 hours. I think this is a complicated process that cannot be understood without that level of expertise, so I think it is necessary for us to do this part in-house.

Tanaka: That is exactly the kind of device. We need to think of the idea of using the data collected by devices such as Fairy Devices as "food for AI," rather than simply sharing the knowledge.

Hido: Yes, that's right.

Tanaka: And since that data is held by that company, it will become [[soft power]] for other companies. It becomes a resource of LLM and AI that only that company can use. This may be the reason why know-how will be converted to software and digitized in the future.

Hido: Yes, that's right. And if there is still a shortage within the company, we could form a consortium and say, "We are competitors, but let's work together," share data, share the models we have created, and strengthen each other to compete with foreign countries.

Tanaka: Yes, thank you.

## Mr. Nakamura

Nakamura: Yes, I agree. I think it is the same as Tokoroten-san's point that "study is necessary for review," and I also think that deep knowledge is necessary to "teach how to do it" in the first place before review, and to teach work not only for LLM but for the whole process, including algorithms before and after. If nothing is done, LLM is about 50% accurate, and to raise that to 80% to 90% requires education.
- There is an analogy I often use to explain this. Can a genius employee come into a department and hand you only the Internet to work with? Most tasks cannot be done without internal manuals and past documentation, no matter how good the person is. You need to be able to communicate that. Technical assistance is provided, including by us, but I think that each and every one of the user companies must be prepared and able to educate themselves about LLM in the end, and be able to go through with it.

Tanaka: Thank you very much. So, relatively anyone can actually use AI, but there are still challenges to overcome in order to actually incorporate it into business operations and increase company productivity.

Nakamura: That's right. One common pattern is for the DX department to support the entire company in using LLM, but the people in the DX department are not experts in each individual business. I think it is important for each department or person in charge to be able to use AI solutions by themselves.

Tanaka: I just remembered an episode when we introduced Slack in our company. Productivity was improved by making the tool for engineers available to all employees. Since then, don't decide whether or not to introduce a tool based on the literacy at the moment. If the literacy level is low, we should educate them. It is important to raise the skill level of all employees. I think Daikin's in-house university is the same way.

Hido: At Daikin, AI personnel are assigned to business units, rather than gathered in a company-wide AI organization. It is important to provide them with the necessary tools and budget so that they can deepen their knowledge of not only AI technology but also each business unit and become [[pi-type human resources]]. For example, we are the second company in Japan to introduce ChatGPT's enterprise plan, which allows unlimited use of AI to those who want to utilize AI in their business units.

Tanaka: I understand that you and Mr. Nakamura are also supporting the implementation of tools, but what are you doing to change the culture of user companies?

Nakamura: It is important not only to provide knowledge, but also to simply help people "gain confidence". People who were not engineers can become "ambassadors" who discover how to use new IT tools, and then create manuals to pass them on. Some people expand the scope of their activities to this themselves, and we hope to support them in creating their first confidence success stories.

Tanaka: I see, so you gain confidence by learning and practicing. Actually, our secretary is also learning Slack and Python, and when an adjustment request comes in on Slack, she uses a Python script to have it posted via Webhook. I'm sure the company's productivity will improve when everyone can do it.

# Q1: Should I learn programming?

Tanaka: Finally, I would like to talk about our future prospects, but before that, I have a few questions coming in, Q1: "I am a non-engineer and want to create a smartphone app using AI, but should I learn programming? Now that we have generative AI, what and how should I learn, should I learn to program, or is there any other means, depending on my objectives, but can anyone give me any answers to this rough question?

Hido: Last week, NVIDIA CEO Jensen sparked a bit of a firestorm when he said "You don't need to learn to program anymore because AI writes code". (ref: [NVIDIA CEO sparks debate by saying "You don't need to learn programming anymore because AI writes code" - GIGAZINE [https://gigazine.net/news/20240227-nvidia-jensen-huang-ai-](https://gigazine.net/news/20240227-nvidia-jensen-huang-ai-) learn-code/])
- There has been a transition of languages from assembler to [[C]] and from C to Python. A leapfrog version of that is happening now. For example, the code that was needed to analyze data in a data scientist's work can now be generated in ChatGPT. However, the work of figuring out what kind of app you really want to make, what kind of functionality is needed to make it happen, the specifications, and putting it into prototype language has to be done by humans. The latter is where the language of what you want to create is put into a plan, and the programming language as a means to realize it, the latter is becoming less and less valuable.

Tanaka: The hurdle to learn has been lowered, I'm a Perl-er so Python is not my forte, but I can generate and use Python code and have the opportunity to learn it, ChatGPT will write it for me and I can paste it in and run it, so I can learn Python! So, in that sense, I think it is possible to use AI to learn programming in the middle stages of becoming a professional if you don't know any programming at all or only know a little bit about it.

Nakayama: As I talked about a little in my slide, the future will be an era where if you write a requirements definition, it will work as is. So in that sense, I am a little skeptical when people say that you should learn programming, you should learn [[requirements definition]].

Tanaka: Oh, I see.

Nakayama: In other words, to write down exactly what needs to be done. If you can do that, the program will be automatically generated, or the words will be executed as they are in the future.

Tanaka: I see.

NAKAMURA: And only where you really need logic, humans write code by hand. Even now, people write code in Python or Perl, and only use C libraries or write in C where speed is really needed. I believe the same thing will happen after this. A future will come where we usually write programs (=requirements) in natural language with LLM, but only write code in regular Python, Perl, or Ruby where we really need speed, security, or certainty.

Tanaka: I see, that's true.

# Q: What kind of human resource development is needed?

Tanaka: Another question came in. We have learned that we need to become smart people, but Japanese companies have trained a homogeneous workforce. In the age of AI, do we need to develop human resources differently?

Nakamura: I feel that everyone is nervous about learning. It's like, "Why don't you go to a convenience store? Programming is as easy as going to a convenience store. It is important to tell people that programming is easy. People have an image of how difficult it was when it was difficult, but it's getting easier and easier. It's as easy as going to a convenience store, so we don't waste time worrying about it.

Tanaka: I can't drive a car, but driving a car is more expensive to learn than programming, so it seems strange that I can drive a car but can't learn to use a computer.

Nakayama: To add a little more, the term "homogeneous human resources" needs to be better defined. The homogenous human resources in Japanese companies are those who can do well even if they are transferred to any department. In the new workplace, the ability to learn and execute tacit knowledge that has not been translated into language in its tacit form is now required. What is required from now on is personnel who can turn tacit knowledge into formal knowledge and make it executable on a computer. The value of personnel who can move personnel and work well together is slowly declining.

Hido: Yes, now that you have put it into words, it makes sense to me. Once formalized and put into the digital world, it can be streamlined and scaled with programming and AI. I think the value lies in how we can drag the business into that world.

Tanaka: Thank you very much. Next, to Mr. Hido, I heard that Daikin is even building a university to nurture human resources. Did the management team have an understanding of AI from the beginning, or did it change over time?

Hido: At some point, management realized that digital talent was very important. They thought about the importance of human resources to do this in their company, and which would be the fastest way to acquire or train them, so they made the decision to send 100 people a year to training, and suddenly started. That is probably different from a normal company. A normal company has to do things more from the bottom up. To be honest, if the HR department said they wanted to recruit AI personnel, they would probably be rejected. However, the top management came down to us and said, "We'll leave it to you to decide how to do it, so let's do it.

Tanaka: Indeed. I am a secretary of the Kansai Association of Corporate Executives, and we have a study session for business managers, and AI has already become an important theme. I feel that they are putting a lot of effort into not only AI but also startups and open innovation. I think it is actually frightening that the future of the company depends on the way the management thinks. It is no use barking at the management when they are not looking, but I hope that what I have just said will convey the fact that a company can change as much as it wants depending on its management.

# Finally
.
Mr. Tanaka: I have to close now, so I would like to ask one question at a time about the prospects for AI and your thoughts on the subject. The remaining questions are: how do you deal with denial promotion, how much risk are you willing to accept, is there anything you think we should learn from this, and can LLM provide facilitation? Please let us know what you think.

Nakayama: Well, let's see, we've been talking about the outlook throughout the past hour, so I don't have anything to say at the end. If I were to talk about the outlook, I would say think about what was happening 10 years ago, what was happening in 2015, what was happening 20 years ago in 2005, and if it was 20 years ago, there are still articles on the web, so you can look at what the world was like back then, and you can see what was going on. There are probably a lot of things that were not possible to do such and such back then. I'll lay out a whole list of which services were released when, and so on. And since this is what happened in 20 years, what will happen in the next 20 years, I don't think it is linear, but I think it is good to look at the future 20 years from the perspective of 20 years ago.

Hido: Since we are here, I have a message for the young people who may be doing unexplored projects in the future. In this session, we have been talking about how to live 5 to 10 years into the future and how to catch the trends, but at the risk of turning things upside down, I would like everyone not to be too influenced by these trends. Right now, for example, VC's are saying that if you want to start a venture business, there is no way but to take advantage of the LLM boom. However, there are already some things that are proceeding on a budget, like a planned economy. It would be unhealthy if we just go along with that. As Noboru mentioned in the first half of the session, we need to create a place that is more like a playground, where we can freely think and explore things that may have a big future impact. I would like you to pursue what you are interested in and what you want to create with free thinking and without being influenced too much.

Nakamura: I just mentioned that LLM may be in a period of slight disillusionment, but I think this year will be a very interesting year with many interesting use cases being found in various industries and sectors. At that time, as the management team mentioned earlier, I would like you to spend not only money but also time. I want you to use your time, try ChatGPT for a bit, and don't give up just because it didn't work out. I hope that you will stick with it and work hard and invest your time until you are ready to use it to the fullest in your own business.

Tanaka: Regarding AI, there are quite a few AI naysayers overseas, but Japan is inevitably forced to use AI due to the declining birthrate, aging population, and productivity improvement. Copyright laws are also favorable for learning. And because of the relative cheapness of IT human resources, more and more foreign AI vendors are coming into the market. However, Japan is not making progress in AI utilization, which I think is a very unbalanced situation. This is the gateway, but don't get too carried away. I would like to leave a message that while unexplored human resources pursue what they want to do, there are also opportunities like this.

---
This page is auto-translated from [/nishio/生成AI/LLM未踏的ビジネス活用最前線](https://scrapbox.io/nishio/生成AI/LLM未踏的ビジネス活用最前線) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.