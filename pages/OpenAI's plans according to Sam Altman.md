---
title: "OpenAI's plans according to Sam Altman"
---

2023-05-29
- [OpenAIâ€™s plans according to Sam Altman](https://humanloop.com/blog/openai-plans)
    - Deleted as of 2023-06-02 [WebArchive](http://web.archive.org/web/20230601163710/https://humanloop.com/blog/openai-plans).
- Japanese translator
    - [https://twitter.com/mlbear2/status/1664207420846120961?s=46&t=gkSZtjGEtUZPO0JCzBxCBw](https://twitter.com/mlbear2/status/1664207420846120961?s=46&t=gkSZtjGEtUZPO0JCzBxCBw)

- GPU resource crunch
    - The reason [[multimodality]] in the early demos of GPT-4 is not available to the public is because we don't have enough GPUs.
    - Longer [[context width]] can be done, but Transformar still can't provide it since it is O(N^2)
    - Related: [[The process of resource exhaustion]].
- Plug-ins are not [[PMF]] except [[WebPilot]].
- The [[scaling rule]] is still in place (because it's eating up computing resources), but it's only increasing at a rate of two to three times per year.

---
This page is auto-translated from [/nishio/OpenAI's plans according to Sam Altman](https://scrapbox.io/nishio/OpenAI's plans according to Sam Altman) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.