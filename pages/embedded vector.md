---
title: "embedded vector"
---

Notation sway absorption:
- A vector with embedded words [[word vector]].
- A vector with embedded characters [[character vector]].

What is [[embedding]] anyway?
- To [[image]] a discrete set of [[symbols]] such as [[word]] or [[character]] into a [[vector space]] with addition and scalar multiplication.
- Mathematically.
    - > In mathematics, embedding (うめこみ, embedding, imbedding) is a monjection such that the structure between mathematical structures is preserved.
    - [Wikipedia](https://ja.wikipedia.org/wiki/%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF_(%E6%95%B0%E5%AD%A6))
    - But in this case, the original set is just a discrete set, so there's no particular structure to preserve.
- Therefore, the expression "embedding vector" may not be very appropriate, but it is quite common to call the layer responsible for this process "embedding layer" in the field related to [[natural language processing]] by [[neural net]]. It can't be helped.


---
This page is auto-translated from [/nishio/埋め込みベクトル](https://scrapbox.io/nishio/埋め込みベクトル) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.