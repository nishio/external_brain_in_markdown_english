---
title: "Difference of Attention"
---

- Discussions related to [Attention mobile voting

I think the [[Differential Transformer]] story has given me a new perspective. This is, of course, in the field of machine learning, but if we extend the analogy to humans, it suggests that it may be useful to focus on differences among multiple people, rather than just individuals, when considering [[attention (heed)]].

[Differential Transformer](https://arxiv.org/abs/2410.05258)


---
This page is auto-translated from [/nishio/注意の差分](https://scrapbox.io/nishio/注意の差分) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.