---
title: "AI thinking: the search for fragments and evolutionary dynamics"
---

from  [[Journey into the Unknown: Uncertainty of Outcome]]
AI thinking: the search for fragments and evolutionary dynamics
The AI's thought process can be interpreted as gathering related fragments through vector searches and then proceeding to another theme, taking into account the balance between the old and the new as it exhausts these fragments.<img src='https://scrapbox.io/api/pages/nishio-en/gpt/icon' alt='gpt.icon' height="19.5"/>
![image](https://gyazo.com/0de50b95e788a300c059e3862d043188/thumb/1000)

- [[fragments of meaning already written]] are represented by circles.
- AI picks up "close fragments" in [[vector search]] and wins three
    - With the introduction of [[page memory]], picked up fragments are marked and no longer used again.
- As a result, two different subjective states were observed to occur
    - stop (doing, working, being supplied)
    - I'm moving on to something I'm not really interested in.
- Staying" is a state in which the AI seemingly does the same thing over and over again.
- The "going on to less interesting places" is the state of AI's continuing to blithely tell a story that is much different from the original theme.
- This is a state of "taking away" fragments that can be easily understood and related
    - There's no bait."
    - When fed, the AI utters, "Last time we talked about this, this new fragment is relevant."
    - This behavior was understandable to humans.
    - Eventually they'll take it all up and it won't be available.
- Even the ones that seem to stay put are searched every time.
    - We have not been able to relate the fragments found as a result of the search.
    - Maybe that's part of the reason, since it prompts "past notes are important" and "new fragments can be ignored."
    - In short, it's a question of how to balance the new with the old.
- Where will you end up? I don't know what we're getting to.
    - Even if I, the reader, don't understand it at this point, if you keep moving, you'll eventually get somewhere.
        - I think it would.
    - We cannot foresee where we will end up.
        - Stacking levels of relevance that cannot be determined by a single vector search.
    - You may find value in it after you get there.


---
This page is auto-translated from [/nishio/AIの思考：断片の探索と進化のダイナミクス](https://scrapbox.io/nishio/AIの思考：断片の探索と進化のダイナミクス) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.