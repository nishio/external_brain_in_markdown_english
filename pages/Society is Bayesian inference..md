---
title: "Society is Bayesian inference."
---

[https://twitter.com/yuiseki_/status/1635915904373637120?s=20](https://twitter.com/yuiseki_/status/1635915904373637120?s=20)
![image](https://gyazo.com/b724f929a4220160e0fc26bb40b8a04c/thumb/1000)![image](https://gyazo.com/958b41cde190f91d71634b1e6dd17ad4/thumb/1000)
![image](https://gyazo.com/185cb03584e090f8f8547415d743678f/thumb/1000)![image](https://gyazo.com/abbc0c7d1d3554f905eaebdbaea2c8d8/thumb/1000)
- [[Tadahiro Taniguchi]]

[https://twitter.com/yuiseki_/status/1636028981676998657?s=20](https://twitter.com/yuiseki_/status/1636028981676998657?s=20)
> The second half of the article is very interesting, as it is based on the assumption that a single stochastic generative model is divided into two parts and that symbols (≒language ≒meaning) are generated by guessing each other's internal representations as they try to optimize their own internal representations.
[https://twitter.com/yuiseki_/status/1636031610230562818?s=20](https://twitter.com/yuiseki_/status/1636031610230562818?s=20)
> In other words, we've already gone beyond the talk about how human cognition might be a probabilistic generative model for better cognition of the world, and the claim that the [[human population]] might also be a probabilistic generative model for better cognition of the world. This is now close to Buddhism. Wisdom of Monju

---
This page is auto-translated from [/nishio/社会はベイズ推論する](https://scrapbox.io/nishio/社会はベイズ推論する) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.