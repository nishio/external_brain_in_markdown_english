---
title: "Reasoning model"
---

<img src='https://scrapbox.io/api/pages/nishio-en/GPT-4.5/icon' alt='GPT-4.5.icon' height="19.5"/>
- The Reasoning model, a large-scale language model (LLM), is a type of LLM designed to effectively handle complex inference tasks. While traditional LLMs generate responses by predicting the next word based on statistical patterns, the Reasoning model decomposes a problem into multiple steps and performs step-by-step inference to produce a more accurate answer.
- For example, OpenAI's "[[o1]]" model released in September 2024 and the "[[o3-mini-high]]" model released in December 2024 have shown better performance than traditional LLMs in math, science, and programming. In addition, in January 2025, DeepSeek, a Chinese company, released "[[DeepSeek-R1]]", a 671 billion-parameter inference model that achieves performance comparable to OpenAI's "o1" model.
- These Reasoning models require more computational resources for each query than traditional LLMs, but they perform better on tasks that require mathematical reasoning and logical thinking.
---
This page is auto-translated from [/nishio/Reasoningモデル](https://scrapbox.io/nishio/Reasoningモデル) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.