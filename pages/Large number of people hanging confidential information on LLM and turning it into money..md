---
title: "Large number of people hanging confidential information on LLM and turning it into money."
---

Context so far
    - [[Work to open up the forest of what has yet to be written.]]
    - [[Semantic Annotation as "Tax Payment]]
    - [[Cryptocurrency as payment for work done for AI]]

> [nishio](https://twitter.com/nishio/status/1642917903090737153) It just occurred to me that if a structure is created in which a huge LLM pays people who give it "useful information that we don't know yet", it is too utopian to assume that people will be engaged in creating new information. I thought that "people will be engaged in creating new information" is too utopian an assumption, and that there will be a large number of "people who will drop secret information to LLMs and turn it into money" before that happens.
- > [nishio](https://twitter.com/nishio/status/1642918622816526336) Is it utopia because we can evolve into an integrated thought body where secrets and lies do not exist? ()

> [0xtkgshn](https://twitter.com/0xtkgshn/status/1642923721718480901) How do you determine what you don't know yet? I'm wondering if you monitor the words that people put in, respond anyway, and let them rate the responses, and the low ones are the "sought-after" ones, and you give back a reward for putting in the domain knowledge there.
- > [nishio](https://twitter.com/nishio/status/1642926068884721664) It's relatively easy to determine "what we don't know yet" and "what is required" but difficult to determine "that the answer is not false". Basically, I think you have to collect a lot of them and throw out the outliers.
    - > [nishio](https://twitter.com/nishio/status/1642926808537640961) wanted: often asked by humans, but not well received for answers
    - >  What we don't know yet (what we didn't know yet): that we can't output the given information by generating a question text that makes the given information the answer and letting the old version answer the question.
- > [0xtkgshn](https://twitter.com/0xtkgshn/status/1642926276309659651) [[peer prediction method]] feeling (the very essence of crowdsourcing)
    - > [0xtkgshn](https://twitter.com/0xtkgshn/status/1642927264739344392) Slightly off topic, but I just remembered that the [[prediction market]] is not just a transaction that benefits the end user, but by looking at the convergence point of that transaction I remember that you can gather information by looking at the convergence point of the transactions. The information you get from the market is more accurate than that of a normal, well-meaning user.
- > [nishio](https://twitter.com/nishio/status/1642927258250907648) Ah, but the style of discarding [[the outlier]] would play "a truth different from most people's expectations"...
    - > [0xtkgshn](https://twitter.com/0xtkgshn/status/1642927473686970368) so I guess it's [[staking]] on determination!
    - > [nishio](https://twitter.com/nishio/status/1642928903068213249) Well, sure. If the information is false, it would be [[ability to deter (an attack, etc.)]] against those who input appropriate information, and if a human decides the amount of wager, can it be regarded as a statement of confidence?
    - > [0xtkgshn](https://twitter.com/0xtkgshn/status/1642930511269052426) Staking is really [[profound]], [[Vitalik]]'s knowledge of game theory and social science is remarkable! Vitalik]'s knowledge of game theory and social science is remarkable.
    - >  [The P + epsilon Attack | Ethereum Foundation Blog](https://blog.ethereum.org/2015/01/28/p-epsilon-attack)
    - >  (Own note)[/tkgshn/The P + epsilon Attack](https://scrapbox.io/tkgshn/The P + epsilon Attack).


> [sirouto](https://twitter.com/sirouto/status/1642926096818786304) I'm sorry to ask a simple question, but would you pay a fee when you can learn for free from the internet?　Even if you buy unknown information, you need credentials. For example, information that "Company A" will launch a new product next year cannot be determined to be true by machine learning of text. Rather, it is likely to take a posting fee, similar to search, and place a link ad in the AI's response.
- > [nishio](https://twitter.com/nishio/status/1642928162635149313) This is after the information that can be learned for free from the internet has been learned and it becomes a race to find out how to get other information. There is no need for AI to do the true/false judgment, just give it to humans and let humans make the judgment on whether it is useful or not.


> [shima__shima](https://twitter.com/shima__shima/status/1642918349922521088) Before that happens, I think there will be a lot of people spouting off random things.
- > [nishio](https://twitter.com/nishio/status/1642919096298930176) If it is determined that you told a lie against other information, your account will be banned and you will die financially [[ability to deter (an attack, etc.)]] will occur.

---
This page is auto-translated from [/nishio/秘密情報をLLMに垂れ込んで金に変える人の大量発生](https://scrapbox.io/nishio/秘密情報をLLMに垂れ込んで金に変える人の大量発生) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.