---
title: "marginal complexity"
---

Software engineers who have experience building complex systems know this firsthand.
- There's a limit to how much [[complexity]] you can tolerate when you're focused and facing the system.
- Limits are lowered when there are interruptions or tasks to be performed in parallel.
    - You can add small features, but you won't be able to implement large ones.
- 'I knew it when I implemented it, but over time I lost track.'
    - This was a system of knowledge that included information in the brain that was not verbalized or documented.
        - Knowledge compresses complexity.
    - I don't know, because over time that knowledge has been lost.
    - When this happens, we have to rediscover our knowledge by deciphering the remaining source code, etc.
        - If this in itself is beyond the feasible cognitive complexity of the person in charge, there's nothing more we can do.

And now, as of 2025, [[AI Agents]] will be added to the story.
- There is a marginal complexity that AI can perform.
    - If you want to add a simple feature, just throw it to the AI and it will do it for you.
    - Complex design changes, for example, may not be settled because the AI gets confused while doing so.
        - This is physically due to the AI agent's context being filled in and becoming progressively dumber and dumber.
        - Devin.ai has been saying this since the beginning, and now I can observe it if I do /context in Claude Code.
            - Should be properly /compact
- This marginal complexity goes up with technological development.
    - Eventually, it will surpass humans.

---
This page is auto-translated from [/nishio/限界複雑さ](https://scrapbox.io/nishio/限界複雑さ) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.