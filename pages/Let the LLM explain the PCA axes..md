---
title: "Let the LLM explain the PCA axes."
---

![image](https://gyazo.com/1fe7f8c5d734e01e901f9fa94979c9e0/thumb/1000)
    - [[2024-09-08-Technology to Support Democracy]] on [Polis-like visualization of the 2022 House of Councillors election
    - Around 1h22
    - Talk about PCA's [[first principal component]] axis coinciding with [[political left/right]].
    - >  [[Bluemo]] I'm curious about the vertical axis.
        - Good idea.
        - [[What is the second principal component?]]

Chat about this comment:.
- [[nodal point of thought 2024-09-14#66e709acaff09e0000254d7e]]
    - In a simple conflict, the contribution of the first principal component should be larger
    - > In other words, whether the distribution of arguments is [[plurality]]/[[multidimensional]]/[[velvety]] or [[one-dimensional]]/[[step]] should be quantifiable by [[principal component analysis]].

It would be interesting to create a [[contribution rate]] for each axis, its direction vector, and a "natural language explanation" for the high-dimensional opinion vector distribution.

---
This page is auto-translated from [/nishio/PCAの軸をLLMに説明させる](https://scrapbox.io/nishio/PCAの軸をLLMに説明させる) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.