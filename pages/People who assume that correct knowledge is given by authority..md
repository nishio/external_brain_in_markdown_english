---
title: "People who assume that correct knowledge is given by authority."
---

> [knshtyk](https://twitter.com/knshtyk/status/1637302053914673152) As was the case during the period when everyone was instantly exposed to image generation AI, there are always people who are spreading their own rules of Prompting (or Prompt Engneering) methods and notations (less effective and more esoteric than regular input) for text AI. I wonder if it's just a typical windfall surrounding generative AI, though there are always people trying to promote Prompting (or Prompt Engneering) methods and notations (less effective and more esoteric than regular input).
>  I think it is a useful trial to find a way to communicate with LLMs, but there are a lot of people who are trying to use it for their own positioning by flaunting their "[[strangely difficult to understand]]" or "[[seemingly great]]" parts, and overall, the unwarranted noise increases and the really useful information is hidden. I would like to ask them to give us a break.

nishio []](https://twitter.com/nishio/status/1637339135152390144) I think this is a phenomenon that generates a feedback loop between "people who assume that correct knowledge is given by an authority" and "people who try to be an authority by giving knowledge-like things with [[full of confidence]] even if they are not correct", when something new appears and there is no [[textbook]] to be an [[authority]] yet. I think it is a phenomenon that generates a feedback loop between "people who believe that correct knowledge can be given by an authority" and "people who try to become an authority by giving knowledge-like things with [[full of confidence]], even if they are not correct".
- People who assume that correct knowledge is given by authority" are eager to have knowledge given to them, and since they do not think of "verifying for themselves whether the knowledge given to them is correct or not," supply and demand are matched.

-----
... I wrote to Scrapbox and this was suggested: [[Two Kinds of Spirituality]].

It is one-sided to think of a cult as "created by a guru," but it can be viewed as a phenomenon in which a system is formed by a combination of a guru and followers, and when that system has the ability to increase followers, it "gradually grows larger and larger." Putting pointlessly complex prompts into AI is like [[cargo cult]] rituals.

>  [[Feynman]] pointed out that the followers of the cargo cult outwardly correctly build airports, headsets, and bamboo "antennas," but the planes never come. Feynman argued that scientists also often fall into that folly, but only imitate the form of such science...which is not worthy of respect or support. --- [Cargo cult - Wikipedia](https://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%BC%E3%82%B4%E3%83%BB%E3%82%AB%E3%83%AB%E3%83%88)

-----
## I think it will be a few more years until we have a large number of people who say "ChatGPT-sama said it, so it's right."

> [okapies](https://twitter.com/okapies/status/1637643975648772096) Similarly, I think it will be a few more years before there are a large number of people who say "ChatGPT is right because he said so".
> [okapies](https://twitter.com/okapies/status/1637659861751324672) If the GPT weights leak or if they succeed in downsizing the model and "[[democratize LLM]]", there will be people who will train themselves to their own convenience and create an [[online guru]]. And I wonder if the offerings to be given in exchange for the "omens" will be cryptocurrency....
> [okapies](https://twitter.com/okapies/status/1637661638097764353) [[Metaverse Festival Hall]], worshippers can receive a fortune (counseling) from [[Oyasama AI]], and worshippers can buy Oyasama's appreciated goods with cryptocurrency, If we make a system like this, Web3, Metaverse and ChatGPT will all be connected (too disgusting...).
    - [[Science Fiction Setting]] : Rather realistic

> [nishio](https://twitter.com/nishio/status/1637654028430741505) There are still tons of people who say "it's right because it was written in a textbook".
> [nishio](https://twitter.com/nishio/status/1637655209152495616) The LLM-generated description is placed on Wikibooks, "This is different from the textbook!" and modify it to fit the textbook, resulting in the textbook content being converted into a format that can be learned by LLMs, and the next LLM will say exactly what the textbook says. This will happen in a few years in areas that already have textbooks and are mainly written in text.


relevance
    - [[One eye-witness is better than many hearsays]]
    - [[Depth syndrome]]
---
This page is auto-translated from [/nishio/正しい知識は権威から与えられると思い込んでる人々](https://scrapbox.io/nishio/正しい知識は権威から与えられると思い込んでる人々) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.