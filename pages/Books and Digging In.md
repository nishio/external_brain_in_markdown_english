---
title: "Books and Digging In"
---

2025-09-18
## ver.2
![image](https://gyazo.com/122e63b835dee86387e0c5174f51941c/thumb/1000)
- D just did a quick read.
- C read it right.
    - I've input what's in the book.
- B is knowledge in the book is also coupled with my own experience
    - I think the ideal after reading is to essentially be in this state here.
        - But it is not generally done because it is very costly.
        - The engineer's intellectual production technique expressed this as "[Hopefully the knowledge in the book will connect with your own experience.
    - How is this ideal state brought about?
        - By luck, you happen to read something in a book and think, "Oh, this is what I experienced before! I've experienced this before!
        - [[Digging until you understand what you don't understand]] Patterns
        - The former is luck, so only the latter can be brought about by effort.

    - [[Books are already a product of abstraction]], so there is no guarantee that they are getting down to "one more hop to a concrete experience" as in C
    - In some cases, it's only written up to D in the first place.
        - I have a feeling it's often the case.


## ver.1
- [[book]] and [[delving into]].
[[digging until you figure out what you don't know]].
![image](https://gyazo.com/122e63b835dee86387e0c5174f51941c/thumb/1000)

- [[Understanding Books]]
    - [[How to connect knowledge from reading a book]]

- [[knowledge consistency]]

- [[Books are already a product of abstraction]]


<img src='https://scrapbox.io/api/pages/nishio-en/GPT5/icon' alt='GPT5.icon' height="19.5"/>
Received. Just a quick abstract üëá.
- Books are "already the product of abstractions. To advance understanding, it is necessary to "dig" abstract words into concrete episodes and connect them to one's own experience.
- The basis of correctness is not "the only authority" but "the consistency network among knowledge. Multiple points of support make it stronger.
- The KJ method is not a "grouping process. First, a mesh is created by using relational lines, then short lines are drawn to the center of density, and the "findings" are verbalized by tabling (summarizing) and then describing them on two or three pieces of paper.
- Moving forward = new insights. The evaluation axis is "shorter lines and fewer crossings" and "more concrete nameplates" rather than "appearance".
- Beware of over-abstraction (leave "earthy"). One-word labels should be "What specifically? For example?" Add in and grow roots.

Thinking Fireworks" light (personal use) that can be turned in 15 minutes
1. one theme (center).
2. take out 10-15 association labels and draw a relationship line on each of the two labels (first, line -> proximity).
3. for long lines with many intersections, move labels to shorten them.
4. 2-3 handwritten enclosures and a front cover (summary).
5. a three-line narrative of "today's findings" at the end.

Operational rules that work immediately (minimum set)
- Abstract labels are treated as prohibited words: "What exactly is X?" Always add in.
- The evaluation is not apparent, but the degree of advancement (new line/tablet/narrative increment).
- When in doubt, follow the order "net -> nameplate -> narrative" (grouping comes later).

Next step (field application)
- Tentatively place a selective schema of relationship labels: `is-a / part-of / cause-of / example-of / contrast-with / supports` (free descriptions are to be placed in the auxiliary column).
- In the study materials, "paper origin/author's discussion" is color-coded, and the source (chapter and section) and location are clearly indicated in footnotes.
- For "hierarchy-ahead" type discussions, first separate the hierarchy (is-a) and net (non-hierarchical edges) into separate layers, and then integrate and visualize them to reduce confusion.
If necessary, I can give you a checklist or Miro/Kozaneba template of the above steps.


---
This page is auto-translated from [/nishio/Êõ∏Á±ç„Å®Êéò„Çä‰∏ã„Åí](https://scrapbox.io/nishio/Êõ∏Á±ç„Å®Êéò„Çä‰∏ã„Åí) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.