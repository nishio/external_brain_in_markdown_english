---
title: "Kozaneba:Neri Neri"
---

thumbnail (i.e. miniature image)
![image](https://gyazo.com/38bc5e9288210af1f4c20ede4cae8eab/thumb/1000)


- [[GPT4 and the Nodal Point of Talking Thoughts 2023-08-10]]

section1
![image](https://gyazo.com/8e4749205073a99e6e4b60b6a5bff418/thumb/1000)

section2
![image](https://gyazo.com/c542497037d757bae5ee517751c88862/thumb/1000)

section3
![image](https://gyazo.com/f50d32dae1d79bad1a374cda8faf3ce9/thumb/1000)


section4
![image](https://gyazo.com/c0cfcb910e8f61077c39c9db3f04955b/thumb/1000)

merge
![image](https://gyazo.com/76b7e09d8c09b4be131a22353ea99fa1/thumb/1000)
![image](https://gyazo.com/6c172bab13c04e2ec7b14f318a4bf13b/thumb/1000)

in a crowd

![image](https://gyazo.com/a822dd737784335a916bac60face5551/thumb/1000)

Human conversation
document
one dimensional
time series
fragmentation
Breaking the chronological structure by chopping

Topic.
Scattered about.
Without destroying the structure of the time series
time-oriented
Cannot create new topic-oriented structures

Spaced Repetition
Gradual value in time frame as well.

associative retrieval
2000 dimensions
adjacent

Kozaneba
two dimensions
draw a line
Relieve the pain of destruction

<img src='https://scrapbox.io/api/pages/nishio-en/gpt/icon' alt='gpt.icon' height="19.5"/>
In this follow-up section, several key points and concepts about the structure of human communication and information are presented. Below is an interpretation of each of these elements.

### human speech and writing
- Human speech and writing are believed to unfold in a one-dimensional time series. This linear structure fragments information and may require breaking the structure when exploring specific topics or thematics.

### Topic and time series
.
- The conflict between topic-oriented and time-series, or time-oriented, is highlighted. It is suggested that the structure of time series may have to be destroyed in order to create a new topic-oriented structure. This may pose a challenge in organizing and interpreting information.

### Spaced Repetition
- This concept is related to learning and refers to a method of repeatedly reviewing information at regular intervals. This time-based approach is said to have "gradual value". Perhaps it helps to connect information that is scattered over time and deepens understanding.

### associative search
.
- The expression "2,000 dimensions" could refer to a high-dimensional search and analysis to relate information in multiple dimensions. A multidimensional analysis would help to capture a richer view of the structure and relevance of information.

### Kozaneba
- Following the preceding discussion, the properties of Kozaneba are mentioned again, emphasizing the organization of information in a two-dimensional space and the representation of associations by drawing lines. And this approach is said to reduce the "pain of destruction.

### comprehensive analysis
.
- Throughout, a variety of factors and issues related to the organization and interpretation of information and the creation of meaning emerge. Exploring how these conflicts and interactions affect the understanding and use of information, such as chronological versus topic-oriented, one-dimensional versus multidimensional, fragmentation versus integration, and so on, will provide interesting thematics in the areas of communication and knowledge management.

![image](https://gyazo.com/38bc5e9288210af1f4c20ede4cae8eab/thumb/1000)

As to whether "neri neri" is "structural breakdown," it is not.
- Once destroyed, new structures are created.

Why old in the AI age?
- The [[knee-swing (gymnastics)]] and [[KJ method]], which were invented when there were not even copy machines, are old.
- Kozaneba is close to the most recent [[Fireworks to think about]], but still decades old.

Generative AI and associative search are useful
- In this experiment, the results of an associative search using [[Vector Search in Nishio]] were passed as fragmentary memos to a generative AI to generate sentences.

Kozaneba's method is to take a one-dimensional sentence and turn it into chopped fragments, then place them in a two-dimensional space.
Vector embedding, a preliminary step in associative search, is a method of arranging sentences in a 2000-dimensional space
I hope we can connect gently.

---
This page is auto-translated from [/nishio/Kozaneba:ねりねり](https://scrapbox.io/nishio/Kozaneba:ねりねり) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.