---
title: "Always in the shadows."
---

2019-01-25
![image](https://gyazo.com/94771e8fc3c1fdae46962ed3d5b9fb9a/thumb/1000)

- Point made by [[Tomoya Tachikawa]] in response to [Pyramid of knowledge
> Vector -> Linear Algebra -> Machine Learning I think, but after learning machine learning without understanding the translation, I have a better understanding of linear algebra.

- In the model I wrote in [Principle that the learning curve is an S-curve
- Acquiring abstract knowledge makes it easier to acquire the concrete knowledge that lies beneath it.
written as
- (Supplemental 2025-09-03: This assumes that the statement "it is easier to acquire specific knowledge at the bottom of it" implicitly assumes that "knowledge at the top" can be acquired before "knowledge at the bottom" is acquired, which is a metaphor for the [[Pyramid of knowledge]] model where knowledge is built up from the bottom and There is a mismatch, isn't there, expressed in a poorly worded way?)

Is this true?
Is the act of "learning machine learning without understanding the translation" really acquiring knowledge directly at a higher level of abstraction?
When you are learning without understanding, are you really learning anything near the top of the pyramid?
Rather, we are learning about shadows on the ground, aren't we?

The tower casts a flat shadow on the ground.
High abstractions have information that corresponds to concrete layers of lower abstraction.
By learning this less abstract information in a way that we don't understand, we accumulate knowledge that "A and B are connected.
When you eventually understand A, A, which was placed on the ground, is lifted higher, and B and C are also pulled upward


2023-07-11
- After four years, they finally bonded.
        - [[Launch and update the model by drawing a conceptual map.]]
- (Supplemented 2025-09-03: This is "I was disappointed when I wrote this ("There is always a shadow") (2019) because the person I spoke to didn't get it, so I was saved by being helpful here ("Standing up and updating the model by drawing a conceptual map", 2013).")


2025-09-03
- Launch and update the model by drawing a conceptual map.
- Connections between elements are preserved when learning at lower concrete layers of abstraction
    - The fact that [[Scrapbox]]/[[Cosense]] is [[Stock of associations]] promotes [retention of connections
    - When [[gathering and arranging information]], it is important to arrange them in a connected state, rather than simply arranging disparate items.
- This is a necessary condition for the occurrence of "When A is eventually understood, A, which was placed on the ground, is lifted high, and B and C are also pulled up.
    - Here A's "[[understanding]]" is spoken of in the metaphor of "[[lifting]]"
        - Why and how does lifting occur?
        - I have a feeling this has something to do with [[Cumulative effect of the KJ method]].
        - The metaphor "[[stand up]]" is used above.
            - I don't know if "get up" or "stand up" is more appropriate.
                - I'm getting the feeling that it occurs on its own, rather than that humans do it intentionally.
                - So I'm a "stand up" guy.
                - Then it's "[[lifting]]" not "[[lifting]]."
- > higher abstractions have information that corresponds to concrete layers of lower abstraction
        - [[combining the concrete with the abstract]].
            - The presence of [[coupling]] encourages [[a back-and-forth between concrete and abstract]].
            - An [[abstract concept]] becomes [[knowledge that has roots]] when it is combined with [[Specific Experience]].
                - [[The Parable of the Floating Grass and the Trees]]
        - [[It is not enough to have pages of concrete facts and pages of abstract concepts]]
        - [[Concrete and abstract combined is not enough]].

---
This page is auto-translated from [/nishio/常に影がある](https://scrapbox.io/nishio/常に影がある) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.