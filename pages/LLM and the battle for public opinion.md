---
title: "LLM and the battle for public opinion"
---

> [tokoroten](https://twitter.com/tokoroten/status/1642776943140671490) Uh, [[LLM]] and [[public opinion poll]] are now connected.
>  Winning the public opinion battle means you can do [[ideological induction]] by biasing the data that the LLM learns.
>  Then, if you contact the LLM, you will only get a specific answer.
>
>  [[(in Christianity) state of truth]] in [[1984]] is an eye opener.
>  That wasn't falsifying the truth, it was fiddling with the data to make the artificial intelligence learn it.

> [tokoroten](https://twitter.com/tokoroten/status/1642801579337351168) Truth Ministry, it's suddenly a lot more realistic to think that it's the ministry that corrects AI training data.
>
>  2+2=5
>  ![image](https://pbs.twimg.com/media/FsxnNsNacAAd25p?format=png&name=900x900#.png)

> [@nishio](https://twitter.com/nishio/status/1642802708972474373?s=46&t=gkSZtjGEtUZPO0JCzBxCBw): @tokoroten Train him 3 times and he'll go crazy (I've done it up to this point, but the Ministry of Truth W didn't connect in my brain)
> ![image](https://pbs.twimg.com/media/Fsg7LwbaAAAhZsA.jpg)
- from  [[Saying the same thing over and over to AI.]]

---
This page is auto-translated from [/nishio/LLMと世論戦](https://scrapbox.io/nishio/LLMと世論戦) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.