---
title: "Will RAG Accelerate Echo Chamber?"
---

from  [[Forkwell Library#55 Questions]]

Does [[RAG]] accelerate [[echo chamber]]?
> [yappy0625](https://x.com/yappy0625/status/1798679401921671580) I'm afraid it might only pick up convenient information or accelerate echo chambers. You could say that it's customized for the individual, but I'm not sure if it's just growing into a convenient AI that will do the discovery for us.
- If you put a [[value judgment]] like "X is evil" in the form of a RAG in the LLM, the probability of that value judgment being reproduced increases, which is probably what you are describing as "echo chamber acceleration.
- On the other hand, as a concrete example of the benefits of this lecture, "A raw LLM does not know about the software Kozaneba is making, so he cannot discuss it, but if he RAGs it, he knows what the software is for and what functions it has, so he can discuss it. We can discuss it."
    - This isn't a "value judgment," it's "[[knowledge sharing]]."
    - Extending knowledge connections, networks, to the "project you are working on now".
    - If it allows my project to move forward more efficiently, it will be of real benefit.
- Even if we want to avoid the risk of echo chambers, choosing "not to put personalized information in the LLM" as a means of achieving this does not seem to balance the advantages and disadvantages.
    - I think it's good to [[be exposed to diverse sources of information]] outside of that LLM.
    - It's easy to switch whether or not to RAG in the first place, so if there are concerns about bias in the "LLM you're reading", just switch to "LLM you're not reading" and use it.
        - Well, I think even LLMs who don't RAG have a bias.
            - I think it's difficult to verify whether the LLM's judgment is wrong or whether "I, who have read very little information but think my judgment is better than the LLM's, who have read a vast amount of information and made a judgment," is wrong.
            - Tried: [[Ask Qarasu-14B a question]].
                - It's a problem before RAG, so I guess the only way is still "exposure to diverse sources of information".
                - You're biased to only read texts written by people within your own country in your own language.
- The technology itself is neutral and can be used in the direction of increasing confirmation bias by affirming one's value judgments, or it can be used to further the discussion by outputting "counterarguments" or "different points of view".
    - It's in the hands of the humans how to use it.
    - Even if you want to output "counterarguments," it is more useful to have an AI that has a good grasp of the project's knowledge to argue with you than an AI that is not familiar with the project and makes misguided statements or makes generalizations without understanding the project's specific circumstances. I think it is still useful to share knowledge with RAGs.
- By the way, I got the vibe from the expressions "accelerating echo chambers" and "discovery" that you seem to implicitly value those things as "evil".
    - I think it's a one-sided view of things to think that echo chambers are evil.
        - [[Filter bubbles and pragmatism]]

---
This page is auto-translated from [/nishio/RAGはエコーチェンバーを加速するか](https://scrapbox.io/nishio/RAGはエコーチェンバーを加速するか) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.