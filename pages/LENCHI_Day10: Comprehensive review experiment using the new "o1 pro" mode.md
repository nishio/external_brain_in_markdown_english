---
title: 'LENCHI_Day10: Comprehensive review experiment using the new "o1 pro" mode'
---

2024-12-08
An experiment was conducted to give all previous manuscripts to ChatGPT o1 pro mode.

---

<img src='https://scrapbox.io/api/pages/nishio-en/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
## What is "o1 pro"?
The "o1" is the state-of-the-art LLM model offered in the ChatGPT Pro plan released by OpenAI on 2014-12-05 and is designed to provide particularly strong performance on difficult problems.
The "o1 pro mode" is a special mode that invests additional computational resources in its o1 model to solve more difficult problems stably and accurately. It is considered particularly useful in areas such as mathematics and programming, where accuracy and reliability of answers are required.

---

I tried to get o1 to write about the experiment itself, but the results were not very interesting.
Interesting part:.
> <img src='https://scrapbox.io/api/pages/nishio-en/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/> Organize from the reader's perspective and establish a policy for improvement:
>  Throughout this entire experiment, we have been able to reaffirm that what is of value to readers is a clear indication of "how to implement intellectual production techniques in the LLM era. The key is not technical details or internal project terminology, but rather the creation of guidelines for readers to know "how to utilize new tools and modes to make information organization, idea generation, and convergence more efficient.

---

<img src='https://scrapbox.io/api/pages/nishio-en/nishio/icon' alt='nishio.icon' height="19.5"/>What's your take on "How to Practice Intellectual Production in the LLM Era" that would be of value to our readers?

<img src='https://scrapbox.io/api/pages/nishio-en/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
When considering "How to Practice Intellectual Production in the LLM Era," what makes it valuable for readers is that it does not remain an abstract theory or introduction of concepts, but provides concrete examples of actual workflows and thought steps. The following are my points from this perspective.

Tool selection and clarification of objectives:
- Various tools exist, such as LLM, Scrapbox, Kozaneba, etc. By clarifying what the reader wants to do, the appropriate tools and functions can be selected. For example, by being aware of goals such as "do I want to generate ideas," "do I want to organize information systematically," or "do I want to deepen existing knowledge and create valuable outputs," readers can choose whether to use LLM for divergence, Kozaneba for convergence and structuring, or Scrapbox for long-term The choice of whether to use LLM for divergence, Kozaneba for convergence and structure, or Scrapbox for a long-term knowledge base will become clearer.

Balance between divergence (idea generation) and convergence (structuring and organizing):
- LLM is excellent at "divergence," which brings out a large number of novel ideas, but without it, we will drown in a flood of ideas. To avoid this, it is necessary to practice convergence using tools after divergence. For example, after obtaining many ideas and perspectives through LLM, it is useful for readers to be shown the process of extracting truly usable ideas by linking related items in Scrapbox and grouping them in Kozaneba.

Presentation of specific examples:
- Specific case studies such as, "When tackling an abstract problem in LLM, what prompts should be thrown at it?" and "How to accumulate daily notes in Scrapbox to provide a useful foundation when passing them on to LLM later? For example, when planning a new service, readers will want to try out the process of "generating 50 ideas about customer needs in LLM, organizing them in Scrapbox, and finally grouping them by market segment in Kozaneba.

Prompt Engineering Basics:
- The key to utilizing LLM is in how you ask the questions. By introducing the technique of asking divergent questions ("Give me as many ideas as you can think of on this topic"), followed by convergent questions ("Divide these into three categories"), and then deeper questions ("Among the ideas in Category A, select the ones that have the highest feasibility"), readers will be able to use LLM as a "thinking partner. By introducing techniques for prompting, readers will be able to use LLM as a "thinking partner.

[[Building a long-term intellectual production ecosystem]]:
- It is essential to create an [[intellectual production infrastructure]] that supports daily activities and the project as a whole, rather than a "one-time prompt and done." Accumulate knowledge fragments little by little in Scrapbox, so that LLM can search and integrate them later. In addition, the results of organizing ideas in Kozaneba can be used in the next ideation session or planning session. Through these iterations and cycles, readers will experience a "[[knowledge loop]]" in which their intellectual activities continue to evolve.

Sharing of failure cases and constraints:
- LLM is not a panacea and can give out incorrect information. It is also important to clearly state examples of failures and constraints so that readers can learn not to expect too much, but to have the attitude to critically examine results and verify them by multiple means. For example, readers will feel more comfortable challenging LLMs if you provide coping strategies, such as "When an LLM gets a fact wrong, check the relevant sources in Scrapbox and compare them in Kozaneba to get closer to the truth."

summary
What is of value to the reader is that it puts the art of intellectual production in the LLM era into "workable guidelines".
- Purpose-driven tool selection and process design
- Specific workflow from divergence to convergence
- Prompt Engineering Tips
- Formation of long-term knowledge loops
- How to deal with risks and failures

By explicitly presenting these ideas, readers will understand "where to start" and "how to combine LLM and digital tools in their daily work and study," and will be able to build their own intellectual production style by actually working with them.


---
This page is auto-translated from [/nishio/LENCHI_Day10：新モード「o1 pro」による総合振り返り実験](https://scrapbox.io/nishio/LENCHI_Day10：新モード「o1 pro」による総合振り返り実験) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.